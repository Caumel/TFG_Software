{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yzuyLp4HCUkX"
   },
   "source": [
    "# **Redes neuronales siamesas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8qNmHTqCUy2"
   },
   "source": [
    "## **Preparacion codigo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1CDM5EPB4lU"
   },
   "source": [
    "### **Importando modulos necesarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1550100164594,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "5UhweCKcBoOo",
    "outputId": "944cd4bb-c8af-47b9-aeb4-b24f41019cf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import,division,print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from PIL import Image as img\n",
    "import cv2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, Flatten, Activation\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYEWUpcrG3Vv"
   },
   "source": [
    "### **Funcion para calcular la distantica L1 punto a punto entre dos vectores y triplet loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH1ZRvQPDtCc"
   },
   "outputs": [],
   "source": [
    "                        \n",
    "def abs_diff_output_shape(input_shapes):\n",
    "  shape1, shape2, shape3= input_shapes\n",
    "  return shape1\n",
    "\n",
    "\n",
    "def distance_vec(y_pred): #Cosine distance\n",
    "  x = y_pred[0]\n",
    "  y = y_pred[1]\n",
    "  z = y_pred[2]\n",
    "  negative = K.prod(K.stack([x, y], axis=1), axis=1)\n",
    "  return negative\n",
    "  \n",
    "  \n",
    "  anchor = y_pred[0]\n",
    "  positive = y_pred[1]\n",
    "  negative = y_pred[2]\n",
    "\n",
    "def get_abs_diff(y_pred):\n",
    "    # L1 distance between two vectors\n",
    "    x = y_pred[0]\n",
    "    y = y_pred[1]\n",
    "    z = y_pred[2]\n",
    "    return K.abs(x - y)\n",
    "\n",
    "\n",
    "def triple_loss(y_true, y_pred):   # y_pred contiene la imagen ancla, positiva y negativa\n",
    "  alpha = 0.1\n",
    "  \n",
    "  anchor = y_pred[0]\n",
    "  positive = y_pred[1]\n",
    "  negative = y_pred[2]\n",
    "    \n",
    "  positive_distance = K.mean(K.square(anchor-positive),axis=-1)  #En principio mean y sum hacen lo mismo excepto que una hace media y otro suma\n",
    "  negative_distance = K.mean(K.square(anchor-negative),axis=-1)\n",
    "  \n",
    "  loss = positive_distance - negative_distance\n",
    "  return K.maximum(loss + alpha, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestSum(unittest.TestCase):\n",
    "\n",
    "    def WhenIWantToGetAnImageThisMustBeRandom(self):\n",
    "        img_groups = {'001' : '001'}\n",
    "        group_names = list(img_groups.keys())\n",
    "        image = get_random_image(img_groups,group_names,int('001'))\n",
    "        self.asserEqual(image,'001001.jpg')\n",
    "        \n",
    "    def WhenIWantToCreateTripletThisMustBeCreated(self):\n",
    "        array1 = create_triplet(1)\n",
    "        array2 = ['001001.jpg','001023.jpg','004003.jpg']\n",
    "        self.asserEqual(array,array2)\n",
    "        \n",
    "    def WhenIWantToLoadAndImageTheImageMustBeLoad(self):\n",
    "        image = cv2.imread('/home/luis/dataset/' + '001' + '/' + '001001.jpg')\n",
    "        image = cv2.resize(image, (96, 96))\n",
    "        image2 = img_to_array(image)\n",
    "        image1 = load_image('001001.jpg')\n",
    "        self.asserEqual(image1,image2)\n",
    "    def WhenIHaveMyTripletsIWantToLoadIt(slef):\n",
    "        triplets = triples_batch(1,image_triples)\n",
    "        images = np.empty([1,3,96,96,3])\n",
    "        for index,i in enumerate(image_triples):\n",
    "            ahs, phs, nhs= i\n",
    "            a = (load_image(ahs),load_image(phs),load_image(nhs))\n",
    "            images[index] = a\n",
    "        self.asserEqual(triplets,images)\n",
    "    def WhenIWantToReshapeMyTripletsThisMustBeReshape(self):\n",
    "        triples_data = create_triplet(1)\n",
    "        image_cache = {}\n",
    "        tr_load_train = triples_batch(tr_train)\n",
    "        tr_load_train_ = reshape(tr_load_train,(96,96,3))\n",
    "        self.asserEqual(tr_load_val_a.shape,(96,96,3))\n",
    "    def WhenIWantToCalculateTheLoss(self):\n",
    "        y_true = 1\n",
    "        triples_data = create_triplet(1)\n",
    "        image_cache = {}\n",
    "        tr_load_train = triples_batch(tr_train)\n",
    "        y_pred = reshape(tr_load_train,(96,96,3))\n",
    "        loss = triple_loss(y_true, y_pred)\n",
    "        self.asserEqual(loss,0)\n",
    "    \n",
    "    def WhenIWantToCalculateTheCosineDistance(self):\n",
    "        y_true = 1\n",
    "        triples_data = create_triplet(1)\n",
    "        image_cache = {}\n",
    "        tr_load_train = triples_batch(tr_train)\n",
    "        y_pred = reshape(tr_load_train,(96,96,3))\n",
    "        distance = distance_vec(y_pred)\n",
    "        self.asserEqual(distance,0)\n",
    "\n",
    "  \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HksRdHOBGsiX"
   },
   "source": [
    "### **Funcion para crear tripletas y cargar las imagenes**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlov2ltiHFGo"
   },
   "outputs": [],
   "source": [
    "def get_random_image(img_groups, group_names, gid):\n",
    "    gname = group_names[gid]\n",
    "    photos = img_groups[gname]\n",
    "    pid = np.random.choice(np.arange(len(photos)), size=1)[0]\n",
    "    pname = photos[pid]\n",
    "    return gname + pname + \".jpg\"\n",
    "   \n",
    "def create_triplet(number_images): # Crea tripleta\n",
    "  img_groups = {}\n",
    "  for folder in  os.listdir('/home/luis/dataset'):\n",
    "    i = 0 \n",
    "    for img_file in os.listdir('/home/luis/dataset/' + folder):\n",
    "      if i == number_images: # Para solo coger 40 fotos\n",
    "        break\n",
    "      prefix, suffix = img_file.split(\".\")\n",
    "      pid = prefix[3:]\n",
    "      if folder in img_groups:\n",
    "          img_groups[folder].append(pid)\n",
    "      else:\n",
    "          img_groups[folder] = [pid]\n",
    "      i += 1\n",
    "  pos_triples, neg_triples, labels = [], [], []\n",
    "  # positive pairs and negative \n",
    "  group_names = list(img_groups.keys())\n",
    "  for key in img_groups.keys():\n",
    "    for i in range(0,number_images):\n",
    "      for j in range(i+1,number_images): # Si dejo i me cogeria duplas con elementos iguales osea (001,001)\n",
    "        inc = random.randrange(1, classes+1)\n",
    "        dn = (int(key) + inc) % classes\n",
    "        right = get_random_image(img_groups, group_names, dn)\n",
    "        pos_triples.append((key + img_groups[key][i] + \".jpg\", key + img_groups[key][j] + \".jpg\", right))\n",
    "  return pos_triples  \n",
    "\n",
    "def load_image(image_name):\n",
    "    image = cv2.imread('/home/luis/dataset/' + image_name[0:3] + '/' + image_name)\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = img_to_array(image)\n",
    "    return image     \n",
    "           \n",
    "def triples_batch(tamaño,image_triples):#, batch_size): #Tripletas\n",
    "    images = np.empty([tamaño,3,96,96,3])\n",
    "    for index,i in enumerate(image_triples):\n",
    "        ahs, phs, nhs= i\n",
    "        a = (load_image(ahs),load_image(phs),load_image(nhs))\n",
    "        images[index] = a\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aniGPta3HVE7"
   },
   "source": [
    "### **Crear red neuronal Convolucional**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlIPAdDyHRcz"
   },
   "outputs": [],
   "source": [
    "def create_base_network(input_dim, classes): # SmallerVGGnet\n",
    "  red = Sequential() \n",
    "  red.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=input_dim))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "  #red.add(Dropout(0.25))\n",
    "  \n",
    "  # (CONV => RELU) * 2 => POOL\n",
    "  red.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  #red.add(Dropout(0.25))\n",
    "  \n",
    "  # (CONV => RELU) * 2 => POOL\n",
    "  red.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  #red.add(Dropout(0.25))\n",
    "  \n",
    "\t# first (and only) set of FC => RELU layers\n",
    "  red.add(Flatten())\n",
    "  red.add(Dense(2048))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization())\n",
    "  red.add(Dropout(0.5))\n",
    "\n",
    "  red.add(Dense(1024))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization())\n",
    "  red.add(Dropout(0.5))\n",
    "\n",
    "  return red "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVpDskYQqno1"
   },
   "source": [
    "## **Principal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EePEpaNqw4a"
   },
   "source": [
    "### **Inicializar datos y normalizarlos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1550100187214,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "DbZ40Cjvp5HQ",
    "outputId": "ae4cc33e-7155-40a9-d5e8-6b8abc80d469"
   },
   "outputs": [],
   "source": [
    "number_images = 4 # Numero de imagenes cogidas\n",
    "classes = 151 # Numero de pokemones\n",
    "batch = 32\n",
    "nb_epoch = 10\n",
    "\n",
    "input_dim = (96,96,3) # Son el ancho el alto y la profundidad de la imagen, 3 al ser en color es la variable input_dim pero todavia no esta tocada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vDF1KvPet_Gy"
   },
   "source": [
    "### Crear varias imagenes apartir de una moviendola o rotandola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes = ['001','002','003','004','005','006','007','008','009',\n",
    "            '010','011','012','013','014','015','016','017','018','019',\n",
    "            '020','021','022','023','024','025','026','027','028','029',\n",
    "            '030','031','032','033','034','035','036','037','038','039',\n",
    "            '040','041','042','043','044','045','046','047','048','049',\n",
    "            '050','051','052','053','054','055','056','057','058','059',\n",
    "            '060','061','062','063','064','065','066','067','068','069',\n",
    "            '070','071','072','073','074','075','076','077','078','079',\n",
    "            '080','081','082','083','084','085','086','087','088','089',\n",
    "            '090','091','092','093','094','095','096','097','098','099',\n",
    "            '100','101','102','103','104','105','106','107','108','109',\n",
    "            '110','111','112','113','114','115','116','117','118','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129',\n",
    "            '130','131','132','133','134','135','136','137','138','139',\n",
    "            '140','141','142','143','144','145','146','147','148','149',\n",
    "            '150','151']\n",
    "\n",
    "def load_image(image_name,i):\n",
    "    image = cv2.imread('/home/luis/dataset/' + image_name + '/' + image_name + i + '.jpg')\n",
    "    print('/home/luis/dataset/' + image_name + '/' + image_name + i + '.jpg')\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = img_to_array(image)\n",
    "    return image    \n",
    "           \n",
    "def triples_batch(tamaño):#, batch_size): #Tripletas\n",
    "    images = np.empty([tamaño,3,96,96,3])\n",
    "    for index,i in enumerate(image_triples):\n",
    "        ahs, phs, nhs= i\n",
    "        a = (load_image(ahs),load_image(phs),load_image(nhs))\n",
    "        images[index] = a\n",
    "    return images\n",
    "\n",
    "a = triples_batch(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXrC8WJ_kmdZ"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/home/luis/dataset',  # this is the target directory\n",
    "        target_size=(256, 256),  # all images will be resized to 150x150\n",
    "        batch_size=16,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#X_train = X_train.reshape(60000, input_dim)\n",
    "#X_test = X_test.reshape(10000, input_dim)\n",
    "#X_train = X_train.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_t5-FJBqAMK"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('/home/luis/database/108.png')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,save_to_dir='/home/luis/', save_prefix='1', save_format='png'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9SCO5vqq78g"
   },
   "source": [
    "### **Crear conjuntos de datos de entrenamiento y test** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGB199xDq8bn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "triples_data = create_triplet(number_images)\n",
    "\n",
    "print(\"# image triples:\", len(triples_data))\n",
    "\n",
    "tm_train = 20000\n",
    "tm_val = 28690\n",
    "\n",
    "tr_train = triples_data[0:tm_train]\n",
    "tr_val = triples_data[tm_train:tm_val]  #El tamaño tiene que ser par (No se mucho por que)\n",
    "\n",
    "print(\"# image triples:\", len(tr_train))\n",
    "print(\"# image triples:\", len(tr_val))\n",
    "\n",
    "image_cache = {}\n",
    "\n",
    "tr_load_train = triples_batch(20000,tr_train)\n",
    "tr_load_val = triples_batch(28690,tr_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1550052298257,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "5XMvIFWd7N45",
    "outputId": "9a0e13bd-f0f4-4fe3-d38c-69f833f5d495",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"# image train triples:\", len(tr_train))\n",
    "[x for x in tr_train[0:5]]\n",
    "\n",
    "print(\"# image validation triples:\", len(tr_val))\n",
    "[x for x in tr_val[0:5]]\n",
    "\n",
    "print(tr_load_train.shape)\n",
    "\n",
    "print(tr_load_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ya7x2IZ4q8mN"
   },
   "source": [
    "### **Crear red siamesa** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3908,
     "status": "ok",
     "timestamp": 1550052305912,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "Tk9pKrRhq8xL",
    "outputId": "2b360ebc-1ccf-4c67-edb6-c2b6caed1f99"
   },
   "outputs": [],
   "source": [
    "# network definition\n",
    "base_network = create_base_network(input_dim, classes)\n",
    "#base_network.summary()\n",
    "\n",
    "\n",
    "anchor_a = Input(shape=(input_dim))   #Nos da un tensor del tamaño input_dim\n",
    "anchor_p = Input(shape=(input_dim))\n",
    "anchor_n = Input(shape=(input_dim))\n",
    "\n",
    "\n",
    "processed_a = base_network(anchor_a)\n",
    "processed_p = base_network(anchor_p)\n",
    "processed_n = base_network(anchor_n)\n",
    "\n",
    "distance = Lambda(distance_vec, output_shape=abs_diff_output_shape)([processed_a, processed_p, processed_n])\n",
    "\n",
    "pred = Dense(1, activation = 'sigmoid')(distance)\n",
    "\n",
    "model = Model(inputs=[anchor_a, anchor_p, anchor_n], outputs=pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dlSqy90sq89q"
   },
   "source": [
    "### **Entrenar modelo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(data,dim):\n",
    "  data_a = data[:, 0].reshape(-1, dim[0], dim[1], dim[2])\n",
    "  data_p = data[:, 1].reshape(-1, dim[0], dim[1], dim[2])\n",
    "  data_n = data[:, 2].reshape(-1, dim[0], dim[1], dim[2])\n",
    "  return [data_a,data_p,data_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nDUFYuEAB9u",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Datos de entrenamiento\n",
    "\n",
    "tr_load_train_ = reshape(tr_load_train,input_dim)\n",
    "tr_load_train_a = tr_load_train_[0]\n",
    "tr_load_train_p = tr_load_train_[1]\n",
    "tr_load_train_n = tr_load_train_[2]\n",
    "\n",
    "print(tr_load_train_a.shape)\n",
    "print(tr_load_train_p.shape)\n",
    "print(tr_load_train_n.shape)\n",
    "\n",
    "#Datos de validacion\n",
    "\n",
    "tr_load_val_ = reshape(tr_load_val,input_dim)\n",
    "tr_load_val_a = tr_load_val_[0]\n",
    "tr_load_val_p = tr_load_val_[1]\n",
    "tr_load_val_n = tr_load_val_[2]\n",
    "\n",
    "print(tr_load_val_a.shape)\n",
    "print(tr_load_val_p.shape)\n",
    "print(tr_load_val_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1550052350856,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "str8zx0HBFXP",
    "outputId": "e43ddd6e-351c-438f-d702-71d3a8dc48a2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3\n",
    "EPOCHS = 100\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=triple_loss, optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAikSlsZEBOI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = np.ones(len(tr_load_train))\n",
    "val = np.ones(len(tr_load_val))\n",
    "a = model.fit([tr_load_train_a,tr_load_train_a,tr_load_train_a], train, batch_size=batch, epochs=nb_epoch, validation_data=([tr_load_val_a,tr_load_val_p,tr_load_val_n], val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1500,
     "status": "ok",
     "timestamp": 1550080484838,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "JLhDWbl_T36_",
    "outputId": "d43db674-e4fd-4167-87d8-d8893445631b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(a.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(a.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(a.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(a.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = load_model('my_model.h5', custom_objects={'triple_loss': triple_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paZXfyDSr0VW"
   },
   "source": [
    "# **Test y prueba en funcionamiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaGMjjXCr6W4"
   },
   "source": [
    "## **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t07kR9viKzMe"
   },
   "outputs": [],
   "source": [
    "def load_data(name, file):\n",
    "  if file == 1:\n",
    "    image = cv2.imread('/home/luis/database/' + name + '.png')\n",
    "  else:\n",
    "    image = cv2.imread('/home/luis/' + name + '.png')\n",
    "  image = cv2.resize(image, (96, 96))\n",
    "  image = img_to_array(image)\n",
    "  return image  \n",
    "\n",
    "def evaluate_data(name):\n",
    "  values = []\n",
    "  for i in range(1,classes+1):\n",
    "    images = []\n",
    "    name1 = str(i)\n",
    "    len_name = len(name1)\n",
    "    if len_name == 1:\n",
    "      name1= '00' + name1\n",
    "    elif len_name == 2:\n",
    "      name1= '0' + name1\n",
    "    images.append((load_data(name, 0),load_data(name1, 1),load_data(name1, 1)))\n",
    "    data = np.array(images, dtype=\"float\") / 255.0\n",
    "    data = reshape(data,input_dim)\n",
    "    values.append(model.predict([data[0],data[1],data[2]]))\n",
    "  return values\n",
    "\n",
    "def draw_image(subplot, image, title):\n",
    "    plt.subplot(subplot)\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "def compare(array1,array2):\n",
    "    a = 0\n",
    "    for i in range(1,(len(array1))):\n",
    "        if array1[i] == array2[i]:\n",
    "            a = a + 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0.3163493]]\n",
      "1 [[0.31739512]]\n",
      "2 [[0.30980086]]\n",
      "3 [[0.31375444]]\n",
      "4 [[0.31566352]]\n",
      "5 [[0.30830926]]\n",
      "6 [[0.31398198]]\n",
      "7 [[0.31006917]]\n",
      "8 [[0.32563713]]\n",
      "9 [[0.31247884]]\n",
      "10 [[0.31220344]]\n",
      "11 [[0.31353167]]\n",
      "12 [[0.31757107]]\n",
      "13 [[0.31062153]]\n",
      "14 [[0.31188396]]\n",
      "15 [[0.31705996]]\n",
      "16 [[0.31196544]]\n",
      "17 [[0.320493]]\n",
      "18 [[0.31149125]]\n",
      "19 [[0.30484328]]\n",
      "20 [[0.312785]]\n",
      "21 [[0.31642532]]\n",
      "22 [[0.31926093]]\n",
      "23 [[0.3237378]]\n",
      "24 [[0.3079819]]\n",
      "25 [[0.31359255]]\n",
      "26 [[0.31019303]]\n",
      "27 [[0.31233883]]\n",
      "28 [[0.3124439]]\n",
      "29 [[0.31781107]]\n",
      "30 [[0.32122785]]\n",
      "31 [[0.32541832]]\n",
      "32 [[0.32130352]]\n",
      "33 [[0.30853862]]\n",
      "34 [[0.31648958]]\n",
      "35 [[0.31152284]]\n",
      "36 [[0.31130135]]\n",
      "37 [[0.31649452]]\n",
      "38 [[0.31142414]]\n",
      "39 [[0.31338474]]\n",
      "40 [[0.3166955]]\n",
      "41 [[0.31792554]]\n",
      "42 [[0.3204138]]\n",
      "43 [[0.3139827]]\n",
      "44 [[0.30984437]]\n",
      "45 [[0.30648968]]\n",
      "46 [[0.30876997]]\n",
      "47 [[0.3190509]]\n",
      "48 [[0.30650255]]\n",
      "49 [[0.32093534]]\n",
      "50 [[0.32153732]]\n",
      "51 [[0.31572214]]\n",
      "52 [[0.31723377]]\n",
      "53 [[0.31262544]]\n",
      "54 [[0.3191659]]\n",
      "55 [[0.30830875]]\n",
      "56 [[0.30845806]]\n",
      "57 [[0.31776124]]\n",
      "58 [[0.31433704]]\n",
      "59 [[0.30902588]]\n",
      "60 [[0.3038433]]\n",
      "61 [[0.31040704]]\n",
      "62 [[0.3172321]]\n",
      "63 [[0.31904146]]\n",
      "64 [[0.3125479]]\n",
      "65 [[0.31377742]]\n",
      "66 [[0.3166239]]\n",
      "67 [[0.31595385]]\n",
      "68 [[0.31383008]]\n",
      "69 [[0.3076884]]\n",
      "70 [[0.31444743]]\n",
      "71 [[0.3152966]]\n",
      "72 [[0.31777203]]\n",
      "73 [[0.31540677]]\n",
      "74 [[0.31072733]]\n",
      "75 [[0.3130004]]\n",
      "76 [[0.30793363]]\n",
      "77 [[0.31409806]]\n",
      "78 [[0.3180514]]\n",
      "79 [[0.31327742]]\n",
      "80 [[0.311299]]\n",
      "81 [[0.30996773]]\n",
      "82 [[0.31429514]]\n",
      "83 [[0.32187968]]\n",
      "84 [[0.32467723]]\n",
      "85 [[0.32359597]]\n",
      "86 [[0.31425053]]\n",
      "87 [[0.313121]]\n",
      "88 [[0.31436974]]\n",
      "89 [[0.32049072]]\n",
      "90 [[0.3148774]]\n",
      "91 [[0.32482854]]\n",
      "92 [[0.31499466]]\n",
      "93 [[0.31095684]]\n",
      "94 [[0.32056665]]\n",
      "95 [[0.31148082]]\n",
      "96 [[0.3142423]]\n",
      "97 [[0.3120602]]\n",
      "98 [[0.3148957]]\n",
      "99 [[0.31769148]]\n",
      "100 [[0.31224668]]\n",
      "101 [[0.30676737]]\n",
      "102 [[0.31485456]]\n",
      "103 [[0.32459205]]\n",
      "104 [[0.31289315]]\n",
      "105 [[0.31670707]]\n",
      "106 [[0.32137987]]\n",
      "107 [[0.31209302]]\n",
      "108 [[0.31383112]]\n",
      "109 [[0.30793455]]\n",
      "110 [[0.31653053]]\n",
      "111 [[0.3104648]]\n",
      "112 [[0.30705756]]\n",
      "113 [[0.31601745]]\n",
      "114 [[0.31672502]]\n",
      "115 [[0.32505068]]\n",
      "116 [[0.31284395]]\n",
      "117 [[0.30742913]]\n",
      "118 [[0.30888775]]\n",
      "119 [[0.30839214]]\n",
      "120 [[0.3107073]]\n",
      "121 [[0.3138731]]\n",
      "122 [[0.32290405]]\n",
      "123 [[0.31373698]]\n",
      "124 [[0.3185445]]\n",
      "125 [[0.3148247]]\n",
      "126 [[0.31307566]]\n",
      "127 [[0.31306285]]\n",
      "128 [[0.3078099]]\n",
      "129 [[0.31542745]]\n",
      "130 [[0.32244727]]\n",
      "131 [[0.31017977]]\n",
      "132 [[0.31670108]]\n",
      "133 [[0.32488742]]\n",
      "134 [[0.30776274]]\n",
      "135 [[0.31082302]]\n",
      "136 [[0.3100704]]\n",
      "137 [[0.31399924]]\n",
      "138 [[0.31543407]]\n",
      "139 [[0.32007518]]\n",
      "140 [[0.31706813]]\n",
      "141 [[0.31275344]]\n",
      "142 [[0.31296462]]\n",
      "143 [[0.3188085]]\n",
      "144 [[0.30440852]]\n",
      "145 [[0.31049535]]\n",
      "146 [[0.32960573]]\n",
      "147 [[0.3284791]]\n",
      "148 [[0.30954313]]\n",
      "149 [[0.31886122]]\n",
      "150 [[0.31159872]]\n"
     ]
    }
   ],
   "source": [
    "x = evaluate_data('001')\n",
    "for index,j in enumerate(x):\n",
    "    print(index,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ",'006','007','008','009',\n",
    "            '010','011','012','013','014','015','016','017','018','019',\n",
    "            '020','021','022','023','024','025','026','027','028','029',\n",
    "            '030','031','032','033','034','035','036','037','038','039',\n",
    "            '040','041','042','043','044','045','046','047','048','049',\n",
    "            '050','051','052','053','054','055','056','057','058','059',\n",
    "            '060','061','062','063','064','065','066','067','068','069',\n",
    "            '070','071','072','073','074','075','076','077','078','079',\n",
    "            '080','081','082','083','084','085','086','087','088','089',\n",
    "            '090','091','092','093','094','095','096','097','098','099','100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76juyf6xYvh9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imagenes = ['001','002','003','004','005']\n",
    "\n",
    "values = []\n",
    "for i in range(0,5):\n",
    "    x = evaluate_data(imagenes[i])\n",
    "    values.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1550081622680,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "j_-e1d8lsDtO",
    "outputId": "12e5212c-a5a6-4925-fe0c-9a4da243d81e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 [[0.3038433]]\n",
      "60 [[0.30486134]]\n",
      "60 [[0.29743245]]\n",
      "60 [[0.30130017]]\n",
      "60 [[0.30316794]]\n",
      "El % de aciertos es:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "aciertos = []\n",
    "for i in values:\n",
    "    var = 1000\n",
    "    index_var = 0\n",
    "    for index,j in enumerate(i):\n",
    "        if j <= var:\n",
    "            var = j\n",
    "            index_var=index\n",
    "    print(index_var,var)\n",
    "    aciertos.append(index_var)\n",
    "    #ref_image = plt.imread(os.path.join('/home/luis/dataset/' + index_var + '.png'))\n",
    "    #draw_image(131,ref_image, \"Pokemon\")\n",
    "    \n",
    " \n",
    "#Accuracy y Matriz de confusión\n",
    "imagenes = list(map(int, imagenes))\n",
    "accuracy = compare(aciertos, imagenes)\n",
    "print('El % de aciertos es: ', accuracy/100, '%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "Q9gjsvw88430",
    "vDF1KvPet_Gy"
   ],
   "name": "TFG Software.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
