{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yzuyLp4HCUkX"
   },
   "source": [
    "# **Redes neuronales siamesas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8qNmHTqCUy2"
   },
   "source": [
    "## **Preparacion codigo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1CDM5EPB4lU"
   },
   "source": [
    "### **Importando modulos necesarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1550100164594,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "5UhweCKcBoOo",
    "outputId": "944cd4bb-c8af-47b9-aeb4-b24f41019cf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import,division,print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from PIL import Image as img\n",
    "import cv2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, Flatten, Activation\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYEWUpcrG3Vv"
   },
   "source": [
    "### **Funcion para calcular la distantica L1 punto a punto entre dos vectores y triplet loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH1ZRvQPDtCc"
   },
   "outputs": [],
   "source": [
    "                        \n",
    "def abs_diff_output_shape(input_shapes):\n",
    "  shape1, shape2, shape3= input_shapes\n",
    "  return shape1\n",
    "\n",
    "\n",
    "def distance_vec(y_pred): #Cosine distance\n",
    "  x = y_pred[0]\n",
    "  y = y_pred[1]\n",
    "  z = y_pred[2]\n",
    "  negative = K.prod(K.stack([x, y], axis=1), axis=1)\n",
    "  return negative\n",
    "  \n",
    "  \n",
    "  anchor = y_pred[0]\n",
    "  positive = y_pred[1]\n",
    "  negative = y_pred[2]\n",
    "\n",
    "def get_abs_diff(y_pred):\n",
    "    # L1 distance between two vectors\n",
    "    x = y_pred[0]\n",
    "    y = y_pred[1]\n",
    "    z = y_pred[2]\n",
    "    return K.abs(x - y)\n",
    "\n",
    "\n",
    "def triple_loss(y_true, y_pred):   # y_pred contiene la imagen ancla, positiva y negativa\n",
    "  alpha = 0.1\n",
    "  \n",
    "  anchor = y_pred[0]\n",
    "  positive = y_pred[1]\n",
    "  negative = y_pred[2]\n",
    "    \n",
    "  positive_distance = K.mean(K.square(anchor-positive),axis=-1)  #En principio mean y sum hacen lo mismo excepto que una hace media y otro suma\n",
    "  negative_distance = K.mean(K.square(anchor-negative),axis=-1)\n",
    "  \n",
    "  loss = positive_distance - negative_distance\n",
    "  return K.maximum(loss + alpha, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestSum(unittest.TestCase):\n",
    "\n",
    "    def WhenIWantToGetAnImageThisMustBeRandom(self):\n",
    "        img_groups = {'001' : '001'}\n",
    "        group_names = list(img_groups.keys())\n",
    "        image = get_random_image(img_groups,group_names,int('001'))\n",
    "        self.asserEqual(image,'001001.jpg')\n",
    "        \n",
    "    def WhenIWantToCreateTripletThisMustBeCreated(self):\n",
    "        array1 = create_triplet(1)\n",
    "        array2 = ['001001.jpg','001023.jpg','004003.jpg']\n",
    "        self.asserEqual(array,array2)\n",
    "        \n",
    "    def WhenIWantToLoadAndImageTheImageMustBeLoad(self):\n",
    "        image = cv2.imread('/home/luis/dataset/' + '001' + '/' + '001')\n",
    "        image = cv2.resize(image, (96, 96))\n",
    "        image2 = img_to_array(image)\n",
    "        image1 = load_image('001001.jpg')\n",
    "        self.asserEqual(image1,image2)\n",
    "    def WhenIHaveMyTripletsIWantToLoadIt(slef):\n",
    "        triplets = triples_batch(image_triples)\n",
    "        images = []\n",
    "        for i in image_triples:\n",
    "          ahs, phs, nhs= i\n",
    "          images.append((load_image(ahs),load_image(phs),load_image(nhs)))\n",
    "        data = np.array(images, dtype=\"float\") / 255.0\n",
    "        self.asserEqual(triplets,data)\n",
    "    def WhenIWantToReshapeMyTripletsThisMustBeReshape(self):\n",
    "        triples_data = create_triplet(1)\n",
    "        image_cache = {}\n",
    "        tr_load_train = triples_batch(tr_train)\n",
    "        tr_load_train_ = reshape(tr_load_train,(96,96,3))\n",
    "        self.asserEqual(tr_load_val_a.shape,(96,96,3))\n",
    "    def WhenIWantToCalculateTheLoss(self):\n",
    "        y_true = 1\n",
    "        triples_data = create_triplet(1)\n",
    "        image_cache = {}\n",
    "        tr_load_train = triples_batch(tr_train)\n",
    "        y_pred = reshape(tr_load_train,(96,96,3))\n",
    "        loss = triple_loss(y_true, y_pred)\n",
    "        self.asserEqual(loss,0)\n",
    "    \n",
    "    def WhenIWantToCalculateTheCosineDistance(self):\n",
    "        y_true = 1\n",
    "        triples_data = create_triplet(1)\n",
    "        image_cache = {}\n",
    "        tr_load_train = triples_batch(tr_train)\n",
    "        y_pred = reshape(tr_load_train,(96,96,3))\n",
    "        distance = distance_vec(y_pred)\n",
    "        self.asserEqual(distance,0)\n",
    "\n",
    "  \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HksRdHOBGsiX"
   },
   "source": [
    "### **Funcion para crear tripletas y cargar las imagenes**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlov2ltiHFGo"
   },
   "outputs": [],
   "source": [
    "def get_random_image(img_groups, group_names, gid):\n",
    "    gname = group_names[gid]\n",
    "    photos = img_groups[gname]\n",
    "    pid = np.random.choice(np.arange(len(photos)), size=1)[0]\n",
    "    pname = photos[pid]\n",
    "    return gname + pname + \".jpg\"\n",
    "   \n",
    "def create_triplet(number_images): # Crea tripleta\n",
    "  img_groups = {}\n",
    "  for folder in  os.listdir('/home/luis/dataset'):\n",
    "    i = 0 \n",
    "    for img_file in os.listdir('/home/luis/dataset/' + folder):\n",
    "      if i == number_images: # Para solo coger 40 fotos\n",
    "        break\n",
    "      prefix, suffix = img_file.split(\".\")\n",
    "      pid = prefix[3:]\n",
    "      if folder in img_groups:\n",
    "          img_groups[folder].append(pid)\n",
    "      else:\n",
    "          img_groups[folder] = [pid]\n",
    "      i += 1\n",
    "  pos_triples, neg_triples, labels = [], [], []\n",
    "  # positive pairs and negative \n",
    "  group_names = list(img_groups.keys())\n",
    "  for key in img_groups.keys():\n",
    "    for i in range(0,number_images):\n",
    "      for j in range(i+1,number_images): # Si dejo i me cogeria duplas con elementos iguales osea (001,001)\n",
    "        inc = random.randrange(1, classes+1)\n",
    "        dn = (int(key) + inc) % classes\n",
    "        right = get_random_image(img_groups, group_names, dn)\n",
    "        pos_triples.append((key + img_groups[key][i] + \".jpg\", key + img_groups[key][j] + \".jpg\", right))\n",
    "  return pos_triples  \n",
    "\n",
    "def load_image(image_name):\n",
    "    image = cv2.imread('/home/luis/dataset/' + image_name[0:3] + '/' + image_name)\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = img_to_array(image)\n",
    "    return image     \n",
    "           \n",
    "def triples_batch(image_triples):#, batch_size): #Tripletas\n",
    "  images = []\n",
    "  for i in image_triples:\n",
    "      ahs, phs, nhs= i\n",
    "      images.append((load_image(ahs),load_image(phs),load_image(nhs)))\n",
    "  data = np.array(images, dtype=\"float\") / 255.0\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aniGPta3HVE7"
   },
   "source": [
    "### **Crear red neuronal Convolucional**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlIPAdDyHRcz"
   },
   "outputs": [],
   "source": [
    "def create_base_network(input_dim, classes): # SmallerVGGnet\n",
    "  red = Sequential() \n",
    "  red.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=input_dim))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "  #red.add(Dropout(0.25))\n",
    "  \n",
    "  # (CONV => RELU) * 2 => POOL\n",
    "  red.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  #red.add(Dropout(0.25))\n",
    "  \n",
    "  # (CONV => RELU) * 2 => POOL\n",
    "  red.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  #red.add(Dropout(0.25))\n",
    "  \n",
    "\t# first (and only) set of FC => RELU layers\n",
    "  red.add(Flatten())\n",
    "  red.add(Dense(2048))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization())\n",
    "  red.add(Dropout(0.5))\n",
    "\n",
    "  red.add(Dense(1024))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization())\n",
    "  red.add(Dropout(0.5))\n",
    "\n",
    "  return red "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVpDskYQqno1"
   },
   "source": [
    "## **Principal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EePEpaNqw4a"
   },
   "source": [
    "### **Inicializar datos y normalizarlos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1550100187214,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "DbZ40Cjvp5HQ",
    "outputId": "ae4cc33e-7155-40a9-d5e8-6b8abc80d469"
   },
   "outputs": [],
   "source": [
    "number_images = 4 # Numero de imagenes cogidas\n",
    "classes = 151 # Numero de pokemones\n",
    "batch = 32\n",
    "nb_epoch = 10\n",
    "\n",
    "input_dim = (96,96,3) # Son el ancho el alto y la profundidad de la imagen, 3 al ser en color es la variable input_dim pero todavia no esta tocada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vDF1KvPet_Gy"
   },
   "source": [
    "### Crear varias imagenes apartir de una moviendola o rotandola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes = ['001','002','003','004','005','006','007','008','009',\n",
    "            '010','011','012','013','014','015','016','017','018','019',\n",
    "            '020','021','022','023','024','025','026','027','028','029',\n",
    "            '030','031','032','033','034','035','036','037','038','039',\n",
    "            '040','041','042','043','044','045','046','047','048','049',\n",
    "            '050','051','052','053','054','055','056','057','058','059',\n",
    "            '060','061','062','063','064','065','066','067','068','069',\n",
    "            '070','071','072','073','074','075','076','077','078','079',\n",
    "            '080','081','082','083','084','085','086','087','088','089',\n",
    "            '090','091','092','093','094','095','096','097','098','099',\n",
    "            '100','101','102','103','104','105','106','107','108','109',\n",
    "            '110','111','112','113','114','115','116','117','118','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129',\n",
    "            '130','131','132','133','134','135','136','137','138','139',\n",
    "            '140','141','142','143','144','145','146','147','148','149',\n",
    "            '150','151']\n",
    "\n",
    "def load_image(image_name,i):\n",
    "    image = cv2.imread('/home/luis/dataset/' + image_name + '/' + image_name + i + '.jpg')\n",
    "    print('/home/luis/dataset/' + image_name + '/' + image_name + i + '.jpg')\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = img_to_array(image)\n",
    "    return image    \n",
    "           \n",
    "def triples_batch():#, batch_size): #Tripletas\n",
    "    images = []\n",
    "    for i in range(0,200):\n",
    "        images.append(load_image('005',imagenes[i]))\n",
    "        data = np.array(images, dtype=\"float\") / 255.0\n",
    "    return data\n",
    "\n",
    "a = triples_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXrC8WJ_kmdZ"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/home/luis/dataset',  # this is the target directory\n",
    "        target_size=(256, 256),  # all images will be resized to 150x150\n",
    "        batch_size=16,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#X_train = X_train.reshape(60000, input_dim)\n",
    "#X_test = X_test.reshape(10000, input_dim)\n",
    "#X_train = X_train.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_t5-FJBqAMK"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('/home/luis/database/108.png')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,save_to_dir='/home/luis/', save_prefix='1', save_format='png'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9SCO5vqq78g"
   },
   "source": [
    "### **Crear conjuntos de datos de entrenamiento y test** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGB199xDq8bn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# image triples: 906\n",
      "# image triples: 800\n",
      "# image triples: 106\n"
     ]
    }
   ],
   "source": [
    "triples_data = create_triplet(number_images)\n",
    "\n",
    "print(\"# image triples:\", len(triples_data))\n",
    "\n",
    "tr_train = triples_data[0:800]\n",
    "tr_val = triples_data[800:906]  #El tamaño tiene que ser par (No se mucho por que)\n",
    "\n",
    "print(\"# image triples:\", len(tr_train))\n",
    "print(\"# image triples:\", len(tr_val))\n",
    "\n",
    "image_cache = {}\n",
    "\n",
    "tr_load_train = triples_batch(tr_train)\n",
    "tr_load_val = triples_batch(tr_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1550052298257,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "5XMvIFWd7N45",
    "outputId": "9a0e13bd-f0f4-4fe3-d38c-69f833f5d495",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# image train triples: 800\n",
      "# image validation triples: 106\n",
      "(800, 3, 96, 96, 3)\n",
      "(106, 3, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"# image train triples:\", len(tr_train))\n",
    "[x for x in tr_train[0:5]]\n",
    "\n",
    "print(\"# image validation triples:\", len(tr_val))\n",
    "[x for x in tr_val[0:5]]\n",
    "\n",
    "print(tr_load_train.shape)\n",
    "\n",
    "print(tr_load_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ya7x2IZ4q8mN"
   },
   "source": [
    "### **Crear red siamesa** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3908,
     "status": "ok",
     "timestamp": 1550052305912,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "Tk9pKrRhq8xL",
    "outputId": "2b360ebc-1ccf-4c67-edb6-c2b6caed1f99"
   },
   "outputs": [],
   "source": [
    "# network definition\n",
    "base_network = create_base_network(input_dim, classes)\n",
    "#base_network.summary()\n",
    "\n",
    "\n",
    "anchor_a = Input(shape=(input_dim))   #Nos da un tensor del tamaño input_dim\n",
    "anchor_p = Input(shape=(input_dim))\n",
    "anchor_n = Input(shape=(input_dim))\n",
    "\n",
    "\n",
    "processed_a = base_network(anchor_a)\n",
    "processed_p = base_network(anchor_p)\n",
    "processed_n = base_network(anchor_n)\n",
    "\n",
    "distance = Lambda(distance_vec, output_shape=abs_diff_output_shape)([processed_a, processed_p, processed_n])\n",
    "\n",
    "pred = Dense(1, activation = 'sigmoid')(distance)\n",
    "\n",
    "model = Model(inputs=[anchor_a, anchor_p, anchor_n], outputs=pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dlSqy90sq89q"
   },
   "source": [
    "### **Entrenar modelo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nDUFYuEAB9u",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 96, 96, 3)\n",
      "(800, 96, 96, 3)\n",
      "(800, 96, 96, 3)\n",
      "(106, 96, 96, 3)\n",
      "(106, 96, 96, 3)\n",
      "(106, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "def reshape(data,dim):\n",
    "  data_a = data[:, 0].reshape(-1, dim[0], dim[1], dim[2])\n",
    "  data_p = data[:, 1].reshape(-1, dim[0], dim[1], dim[2])\n",
    "  data_n = data[:, 2].reshape(-1, dim[0], dim[1], dim[2])\n",
    "  return [data_a,data_p,data_n]\n",
    "\n",
    "#Datos de entrenamiento\n",
    "\n",
    "tr_load_train_ = reshape(tr_load_train,input_dim)\n",
    "tr_load_train_a = tr_load_train_[0]\n",
    "tr_load_train_p = tr_load_train_[1]\n",
    "tr_load_train_n = tr_load_train_[2]\n",
    "\n",
    "print(tr_load_train_a.shape)\n",
    "print(tr_load_train_p.shape)\n",
    "print(tr_load_train_n.shape)\n",
    "\n",
    "#Datos de validacion\n",
    "\n",
    "tr_load_val_ = reshape(tr_load_val,input_dim)\n",
    "tr_load_val_a = tr_load_val_[0]\n",
    "tr_load_val_p = tr_load_val_[1]\n",
    "tr_load_val_n = tr_load_val_[2]\n",
    "\n",
    "print(tr_load_val_a.shape)\n",
    "print(tr_load_val_p.shape)\n",
    "print(tr_load_val_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1550052350856,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "str8zx0HBFXP",
    "outputId": "e43ddd6e-351c-438f-d702-71d3a8dc48a2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1024)         19169152    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1024)         0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "                                                                 sequential_2[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            1025        lambda_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 19,170,177\n",
      "Trainable params: 19,163,201\n",
      "Non-trainable params: 6,976\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-3\n",
    "EPOCHS = 100\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=triple_loss, optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAikSlsZEBOI",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 106 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 51s 64ms/step - loss: 0.2203 - acc: 0.3225 - val_loss: 0.2282 - val_acc: 0.6604\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 54s 68ms/step - loss: 0.1325 - acc: 0.2412 - val_loss: 0.3283 - val_acc: 0.6321\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 50s 63ms/step - loss: 0.2666 - acc: 0.1925 - val_loss: 0.3954 - val_acc: 0.4811\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 52s 65ms/step - loss: 0.1810 - acc: 0.1750 - val_loss: 0.3208 - val_acc: 0.6792\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 56s 70ms/step - loss: 0.1609 - acc: 0.1600 - val_loss: 0.3621 - val_acc: 0.5189\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 50s 63ms/step - loss: 0.1220 - acc: 0.0688 - val_loss: 0.6373 - val_acc: 0.5377\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 51s 64ms/step - loss: 0.1023 - acc: 0.0462 - val_loss: 0.6894 - val_acc: 0.5472\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 52s 65ms/step - loss: 0.0956 - acc: 0.0387 - val_loss: 0.5974 - val_acc: 0.5094\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 50s 63ms/step - loss: 0.0863 - acc: 0.0513 - val_loss: 0.4332 - val_acc: 0.5377\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 51s 63ms/step - loss: 0.1348 - acc: 0.0650 - val_loss: 0.0619 - val_acc: 0.6038\n"
     ]
    }
   ],
   "source": [
    "train = np.ones(len(tr_load_train))\n",
    "val = np.ones(len(tr_load_val))\n",
    "a = model.fit([tr_load_train_a,tr_load_train_a,tr_load_train_a], train, batch_size=batch, epochs=nb_epoch, validation_data=([tr_load_val_a,tr_load_val_p,tr_load_val_n], val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1500,
     "status": "ok",
     "timestamp": 1550080484838,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "JLhDWbl_T36_",
    "outputId": "d43db674-e4fd-4167-87d8-d8893445631b",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-72dcb4dd8e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m211\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"best\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'history'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAACSCAYAAABIW82mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADWtJREFUeJzt3X2MXNV9xvHvE4NBJbw4sSMRY4NpTcBBFS9TQhQ1SRswjv+wIyVNjEIDiMYtDamUtJGIopbKKG2atEJCdQtGsZJUKoZQKd1WRBaNoVRVTDwuhGBHbhaXl41RIdghbXm1efrHvdYO613P9ezszLLn+Ugjzz333PFvjnbn2Xvmvsg2ERFRrrcMu4CIiBiuBEFEROESBBERhUsQREQULkEQEVG4BEFEROESBBERhUsQRNEkPSHpsmHXETFMCYKIiMIlCCImIenTkkYl7Zc0Iumddbsk3SLpWUkvSHpU0vn1utWSdkv6H0k/lfRHw30XEc0kCCImkPSbwJ8DHwdOB54EttSrVwLvB84BTgM+ATxfr/s68Lu2TwbOB7YNsOyInh037AIiZqFPAptt/weApC8CBySdBbwGnAycC/zA9o87tnsNWCHph7YPAAcGWnVEj7JHEHGkd1LtBQBg+3+p/upfbHsb8NfARuC/JW2SdErd9aPAauBJSf8q6b0DrjuiJwmCiCPtA848vCDpJODtwE8BbN9q+2Lg3VRTRF+o23fYXgu8A/gOcPeA647oSYIgAo6XdOLhB9UH+LWSLpB0AvBnwEO2n5D0a5LeI+l44P+Al4FDkuZL+qSkU22/BvwCODS0dxRxDBIEEXAv8FLH49eBPwb+AXgG+GVgXd33FOAOqvn/J6mmjP6yXvfbwBOSfgH8HnDVgOqPmBblxjQREWXLHkFEROG6BoGkzfXJM49NsV6Sbq1PvnlU0kUd666W9JP6cXU/C4+IiP5oskfwDWDVUdZ/GFheP9YDfwsg6W3ATcB7gEuAmyQtmE6xERHRf12DwPaDwP6jdFkLfMuV7cBpkk4HrgDus72/PrnmPo4eKBERMQT9+I5gMfB0x/JY3TZVe0REzCL9uMSEJmnzUdqPfAFpPdW0EieddNLF5557bh/Kiogox86dO39me1Ev2/YjCMaAJR3LZ1CdmTkGfHBC+wOTvYDtTcAmgFar5Xa73YeyIiLKIenJ7r0m14+poRHgU/XRQ5cCL9h+BtgKrJS0oP6SeGXdFhERs0jXPQJJd1L9Zb9Q0hjVkUDHA9i+jeqszNXAKPAicG29br+km4Ed9UttsH20L50jImIIugaB7Su7rDfwmSnWbQY291ZaREQMQs4sjogoXIIgIqJwCYKIiMIlCCIiCpcgiIgoXIIgIqJwCYKIiMIlCCIiCpcgiIgoXIIgIqJwCYKIiMIlCCIiCpcgiIgoXIIgIqJwCYKIiMIlCCIiCtcoCCStkrRH0qikGydZf4ukR+rHf0r6ece6Qx3rRvpZfERETF+TW1XOAzYCl1PdkH6HpBHbuw/3sf25jv6fBS7seImXbF/Qv5IjIqKfmuwRXAKM2t5r+1VgC7D2KP2vBO7sR3ERETHzmgTBYuDpjuWxuu0Iks4ElgHbOppPlNSWtF3SR3quNCIiZkTXqSFAk7R5ir7rgHtsH+poW2p7n6SzgW2SfmT78Tf8B9J6YD3A0qVLG5QUERH90mSPYAxY0rF8BrBvir7rmDAtZHtf/e9e4AHe+P3B4T6bbLdstxYtWtSgpIiI6JcmQbADWC5pmaT5VB/2Rxz9I+ldwALg+x1tCySdUD9fCLwP2D1x24iIGJ6uU0O2D0q6AdgKzAM2294laQPQtn04FK4EttjunDY6D7hd0utUofOVzqONIiJi+PTGz+3ha7Vabrfbwy4jIuJNRdJO261ets2ZxRERhUsQREQULkEQEVG4BEFEROESBBERhUsQREQULkEQEVG4BEFEROESBBERhUsQREQULkEQEVG4BEFEROESBBERhUsQREQULkEQEVG4BEFEROEaBYGkVZL2SBqVdOMk66+R9JykR+rH73Ssu1rST+rH1f0sPiIipq/rrSolzQM2ApdT3ch+h6SRSW45eZftGyZs+zbgJqAFGNhZb3ugL9VHRMS0NdkjuAQYtb3X9qvAFmBtw9e/ArjP9v76w/8+YFVvpUZExExoEgSLgac7lsfqtok+KulRSfdIWnIs20paL6ktqf3cc881LD0iIvqhSRBokraJd7z/J+As278K/AvwzWPYFtubbLdstxYtWtSgpIiI6JcmQTAGLOlYPgPY19nB9vO2X6kX7wAubrptREQMV5Mg2AEsl7RM0nxgHTDS2UHS6R2La4Af18+3AislLZC0AFhZt0VExCzR9agh2wcl3UD1AT4P2Gx7l6QNQNv2CPAHktYAB4H9wDX1tvsl3UwVJgAbbO+fgfcRERE9kn3ElP1QtVott9vtYZcREfGmImmn7VYv2+bM4oiIwiUIIiIKlyCIiChcgiAionAJgoiIwiUIIiIKlyCIiChcgiAionAJgoiIwiUIIiIKlyCIiChcgiAionAJgoiIwiUIIiIKlyCIiChcoyCQtErSHkmjkm6cZP3nJe2ub17/PUlndqw7JOmR+jEycduIiBiurncokzQP2AhcTnUP4h2SRmzv7uj2MNCy/aKk64GvAp+o171k+4I+1x0REX3SZI/gEmDU9l7brwJbgLWdHWzfb/vFenE71U3qIyLiTaBJECwGnu5YHqvbpnId8N2O5RMltSVtl/SRHmqMiIgZ1HVqCNAkbZPe6FjSVUAL+EBH81Lb+ySdDWyT9CPbj0/Ybj2wHmDp0qWNCo+IiP5oskcwBizpWD4D2Dexk6TLgC8Ba2y/crjd9r76373AA8CFE7e1vcl2y3Zr0aJFx/QGIiJiepoEwQ5guaRlkuYD64A3HP0j6ULgdqoQeLajfYGkE+rnC4H3AZ1fMkdExJB1nRqyfVDSDcBWYB6w2fYuSRuAtu0R4GvAW4FvSwJ4yvYa4DzgdkmvU4XOVyYcbRQREUMme9Lp/qFptVput9vDLiMi4k1F0k7brV62zZnFERGFSxBERBQuQRARUbgEQURE4RIEERGFSxBERBQuQRARUbgEQURE4RIEERGFSxBERBQuQRARUbgEQURE4RIEERGFSxBERBQuQRARUbgEQURE4RoFgaRVkvZIGpV04yTrT5B0V73+IUlndaz7Yt2+R9IV/Ss9IiL6oWsQSJoHbAQ+DKwArpS0YkK364ADtn8FuAX4i3rbFVT3OH43sAr4m/r1IiJilmiyR3AJMGp7r+1XgS3A2gl91gLfrJ/fA3xI1c2L1wJbbL9i+7+A0fr1IiJilmgSBIuBpzuWx+q2SfvYPgi8ALy94bYRETFExzXoo0naJt7xfqo+TbZF0npgfb34iqTHGtRVgoXAz4ZdxCyRsRiXsRiXsRj3rl43bBIEY8CSjuUzgH1T9BmTdBxwKrC/4bbY3gRsApDUtt1q+gbmsozFuIzFuIzFuIzFOEntXrdtMjW0A1guaZmk+VRf/o5M6DMCXF0//xiwzbbr9nX1UUXLgOXAD3otNiIi+q/rHoHtg5JuALYC84DNtndJ2gC0bY8AXwf+TtIo1Z7AunrbXZLuBnYDB4HP2D40Q+8lIiJ60GRqCNv3AvdOaPuTjucvA781xbZfBr58DDVtOoa+c13GYlzGYlzGYlzGYlzPY6FqBiciIkqVS0xERBRuaEEwnctWzDUNxuLzknZLelTS9ySdOYw6B6HbWHT0+5gkS5qzR4w0GQtJH69/NnZJ+vtB1zgoDX5Hlkq6X9LD9e/J6mHUOdMkbZb07FSH2Ktyaz1Oj0q6qNEL2x74g+pL58eBs4H5wA+BFRP6/D5wW/18HXDXMGqdJWPxG8Av1c+vL3ks6n4nAw8C24HWsOse4s/FcuBhYEG9/I5h1z3EsdgEXF8/XwE8Mey6Z2gs3g9cBDw2xfrVwHepzuG6FHioyesOa49gOpetmGu6joXt+22/WC9upzofYy5q8nMBcDPwVeDlQRY3YE3G4tPARtsHAGw/O+AaB6XJWBg4pX5+KpOcrzQX2H6Q6sjMqawFvuXKduA0Sad3e91hBcF0Llsx1xzrZTiuo0r8uajrWEi6EFhi+58HWdgQNPm5OAc4R9K/S9ouadXAqhusJmPxp8BVksaojnD87GBKm3V6uqxPo8NHZ8B0Llsx1zR+n5KuAlrAB2a0ouE56lhIegvV1W2vGVRBQ9Tk5+I4qumhD1LtJf6bpPNt/3yGaxu0JmNxJfAN238l6b1U5zWdb/v1mS9vVunpc3NYewTHctkKJly2Yq5pdBkOSZcBXwLW2H5lQLUNWrexOBk4H3hA0hNUc6Ajc/QL46a/I/9o+zVXV/fdQxUMc02TsbgOuBvA9veBE6muQ1SaRp8nEw0rCKZz2Yq5putY1NMht1OFwFydB4YuY2H7BdsLbZ9l+yyq70vW2O75GiuzWJPfke9QHUiApIVUU0V7B1rlYDQZi6eADwFIOo8qCJ4baJWzwwjwqfrooUuBF2w/022joUwNeRqXrZhrGo7F14C3At+uvy9/yvaaoRU9QxqORREajsVWYKWk3cAh4Au2nx9e1TOj4Vj8IXCHpM9RTYVcMxf/cJR0J9VU4ML6+5CbgOMBbN9G9f3Iaqp7v7wIXNvodefgWEVExDHImcUREYVLEEREFC5BEBFRuARBREThEgQREYVLEEREFC5BEBFRuARBRETh/h8CcUItN757oQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(a.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(a.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(a.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(a.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = load_model('my_model.h5', custom_objects={'triple_loss': triple_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paZXfyDSr0VW"
   },
   "source": [
    "# **Test y prueba en funcionamiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaGMjjXCr6W4"
   },
   "source": [
    "## **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t07kR9viKzMe"
   },
   "outputs": [],
   "source": [
    "def load_data(name, file):\n",
    "  if file == 1:\n",
    "    image = cv2.imread('/home/luis/database/' + name + '.png')\n",
    "  else:\n",
    "    image = cv2.imread('/home/luis/' + name + '.png')\n",
    "  image = cv2.resize(image, (96, 96))\n",
    "  image = img_to_array(image)\n",
    "  return image  \n",
    "\n",
    "def evaluate_data(name):\n",
    "  values = []\n",
    "  for i in range(1,classes+1):\n",
    "    images = []\n",
    "    name1 = str(i)\n",
    "    len_name = len(name1)\n",
    "    if len_name == 1:\n",
    "      name1= '00' + name1\n",
    "    elif len_name == 2:\n",
    "      name1= '0' + name1\n",
    "    images.append((load_data(name, 0),load_data(name1, 1),load_data(name1, 1)))\n",
    "    data = np.array(images, dtype=\"float\") / 255.0\n",
    "    data = reshape(data,input_dim)\n",
    "    values.append(model.predict([data[0],data[1],data[2]]))\n",
    "  return values\n",
    "\n",
    "def draw_image(subplot, image, title):\n",
    "    plt.subplot(subplot)\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "def compare(array1,array2):\n",
    "    a = 0\n",
    "    for i in range(1,(len(array1))):\n",
    "        if array1[i] == array2[i]:\n",
    "            a = a + 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76juyf6xYvh9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imagenes = ['001','002','003','004','005','006','007','008','009',\n",
    "            '010','011','012','013','014','015','016','017','018','019',\n",
    "            '020','021','022','023','024','025','026','027','028','029',\n",
    "            '030','031','032','033','034','035','036','037','038','039',\n",
    "            '040','041','042','043','044','045','046','047','048','049',\n",
    "            '050','051','052','053','054','055','056','057','058','059',\n",
    "            '060','061','062','063','064','065','066','067','068','069',\n",
    "            '070','071','072','073','074','075','076','077','078','079',\n",
    "            '080','081','082','083','084','085','086','087','088','089',\n",
    "            '090','091','092','093','094','095','096','097','098','099','100']\n",
    "\n",
    "values = []\n",
    "for i in range(0,100):\n",
    "    x = evaluate_data(imagenes[i])\n",
    "    values.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1550081622680,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "j_-e1d8lsDtO",
    "outputId": "12e5212c-a5a6-4925-fe0c-9a4da243d81e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[4.8836355e-05]]\n",
      "0 [[0.00062587]]\n",
      "107 [[0.0148457]]\n",
      "37 [[0.0465007]]\n",
      "37 [[0.06473316]]\n",
      "37 [[0.03937604]]\n",
      "100 [[0.00041709]]\n",
      "100 [[0.00014814]]\n",
      "0 [[0.001436]]\n",
      "37 [[0.0504053]]\n",
      "37 [[0.11052747]]\n",
      "0 [[0.0027138]]\n",
      "107 [[0.06849933]]\n",
      "37 [[0.10753403]]\n",
      "49 [[0.01433289]]\n",
      "37 [[0.18454395]]\n",
      "37 [[0.08004609]]\n",
      "37 [[0.03183141]]\n",
      "49 [[0.01368834]]\n",
      "37 [[0.10581428]]\n",
      "37 [[0.06519576]]\n",
      "37 [[0.02729935]]\n",
      "0 [[0.00330165]]\n",
      "0 [[0.00151983]]\n",
      "37 [[0.14766243]]\n",
      "37 [[0.09588894]]\n",
      "37 [[0.09626689]]\n",
      "37 [[0.09430076]]\n",
      "100 [[1.5562615e-05]]\n",
      "100 [[0.00014542]]\n",
      "100 [[0.00017211]]\n",
      "100 [[0.00107538]]\n",
      "100 [[0.00313546]]\n",
      "100 [[0.00717238]]\n",
      "34 [[8.003998e-06]]\n",
      "34 [[6.345438e-05]]\n",
      "58 [[0.11666754]]\n",
      "37 [[0.00074488]]\n",
      "100 [[0.0005252]]\n",
      "0 [[0.00041907]]\n",
      "34 [[0.01607562]]\n",
      "107 [[0.03461677]]\n",
      "37 [[0.02882623]]\n",
      "37 [[0.02547685]]\n",
      "100 [[0.00665937]]\n",
      "37 [[0.0500854]]\n",
      "0 [[0.01307755]]\n",
      "100 [[0.00243916]]\n",
      "100 [[0.01667038]]\n",
      "0 [[0.00017656]]\n",
      "0 [[0.00100442]]\n",
      "49 [[0.01535733]]\n",
      "49 [[0.02721876]]\n",
      "0 [[0.00214965]]\n",
      "100 [[0.00081126]]\n",
      "107 [[0.03032222]]\n",
      "0 [[0.02535542]]\n",
      "0 [[0.00648127]]\n",
      "58 [[0.0270084]]\n",
      "100 [[0.00901178]]\n",
      "100 [[0.00617806]]\n",
      "100 [[0.01444975]]\n",
      "37 [[0.0395325]]\n",
      "37 [[0.08551452]]\n",
      "37 [[0.058596]]\n",
      "100 [[0.00096959]]\n",
      "100 [[0.00064626]]\n",
      "100 [[0.01131717]]\n",
      "37 [[0.04403337]]\n",
      "107 [[0.07777567]]\n",
      "37 [[0.06856188]]\n",
      "100 [[0.00228563]]\n",
      "49 [[0.00565069]]\n",
      "34 [[0.05273711]]\n",
      "34 [[0.02931446]]\n",
      "0 [[0.00264263]]\n",
      "37 [[0.09119476]]\n",
      "58 [[0.04491684]]\n",
      "0 [[0.00791874]]\n",
      "0 [[0.00109758]]\n",
      "100 [[0.01423144]]\n",
      "49 [[0.00809135]]\n",
      "0 [[0.01144064]]\n",
      "37 [[0.04361514]]\n",
      "37 [[0.03741575]]\n",
      "100 [[0.00033079]]\n",
      "100 [[0.00109275]]\n",
      "100 [[0.00207466]]\n",
      "100 [[0.01966699]]\n",
      "100 [[0.00177342]]\n",
      "100 [[0.00212621]]\n",
      "49 [[0.0071321]]\n",
      "100 [[0.00325954]]\n",
      "100 [[0.00126827]]\n",
      "49 [[0.00848933]]\n",
      "37 [[0.08583403]]\n",
      "114 [[0.04079406]]\n",
      "37 [[0.05496367]]\n",
      "37 [[0.03904588]]\n",
      "100 [[3.6681704e-05]]\n",
      "El % de aciertos es:  0.01 %\n"
     ]
    }
   ],
   "source": [
    "aciertos = []\n",
    "for i in values:\n",
    "    var = 1000\n",
    "    index_var = 0\n",
    "    for index,j in enumerate(i):\n",
    "        if j <= var:\n",
    "            var = j\n",
    "            index_var=index\n",
    "    print(index_var,var)\n",
    "    aciertos.append(index_var)\n",
    "    #ref_image = plt.imread(os.path.join('/home/luis/dataset/' + index_var + '.png'))\n",
    "    #draw_image(131,ref_image, \"Pokemon\")\n",
    "    \n",
    " \n",
    "#Accuracy y Matriz de confusión\n",
    "imagenes = list(map(int, imagenes))\n",
    "accuracy = compare(aciertos, imagenes)\n",
    "print('El % de aciertos es: ', accuracy/100, '%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "Q9gjsvw88430",
    "vDF1KvPet_Gy"
   ],
   "name": "TFG Software.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
