{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yzuyLp4HCUkX"
   },
   "source": [
    "# **Redes neuronales siamesas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8qNmHTqCUy2"
   },
   "source": [
    "## **Preparacion codigo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1CDM5EPB4lU"
   },
   "source": [
    "### **Importando modulos necesarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1550100164594,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "5UhweCKcBoOo",
    "outputId": "944cd4bb-c8af-47b9-aeb4-b24f41019cf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import,division,print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from PIL import Image as img\n",
    "import cv2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, Flatten, Activation\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYEWUpcrG3Vv"
   },
   "source": [
    "### **Funcion para calcular la distantica L1 punto a punto entre dos vectores y triplet loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH1ZRvQPDtCc"
   },
   "outputs": [],
   "source": [
    "                        \n",
    "def abs_diff_output_shape(input_shapes):\n",
    "  shape1, shape2, shape3= input_shapes\n",
    "  return shape1\n",
    "\n",
    "\n",
    "def distance_vec(y_pred): #Cosine distance\n",
    "  x = y_pred[0]\n",
    "  y = y_pred[1]\n",
    "  z = y_pred[2]\n",
    "  negative = K.prod(K.stack([x, y], axis=1), axis=1)\n",
    "  return negative\n",
    "  \n",
    "  \n",
    "  anchor = y_pred[0]\n",
    "  positive = y_pred[1]\n",
    "  negative = y_pred[2]\n",
    "\n",
    "def get_abs_diff(y_pred):\n",
    "    # L1 distance between two vectors\n",
    "    x = y_pred[0]\n",
    "    y = y_pred[1]\n",
    "    z = y_pred[2]\n",
    "    return K.abs(x - y)\n",
    "\n",
    "\n",
    "def triple_loss(y_true, y_pred):   # y_pred contiene la imagen ancla, positiva y negativa\n",
    "  alpha = 0.1\n",
    "  \n",
    "  anchor = y_pred[0]\n",
    "  positive = y_pred[1]\n",
    "  negative = y_pred[2]\n",
    "    \n",
    "  positive_distance = K.mean(K.square(anchor-positive),axis=-1)  #En principio mean y sum hacen lo mismo excepto que una hace media y otro suma\n",
    "  negative_distance = K.mean(K.square(anchor-negative),axis=-1)\n",
    "  \n",
    "  loss = positive_distance - negative_distance\n",
    "  return K.maximum(loss + alpha, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestSum(unittest.TestCase):\n",
    "\n",
    "    def WhenIWantToGetAnImageThisMustBeRandom(self):\n",
    "        img_groups = {'001' : '001'}\n",
    "        group_names = list(img_groups.keys())\n",
    "        image = get_random_image(img_groups,group_names,int('001'))\n",
    "        self.asserEqual(image,'001001.jpg')\n",
    "        \n",
    "    def WhenIWantToCreateTripletThisMustBeCreated(self):\n",
    "        array1 = create_triplet(1)\n",
    "        array2 = ['001001.jpg','001023.jpg','004003.jpg']\n",
    "        self.asserEqual(array,array2)\n",
    "        \n",
    "    def WhenIWantToLoadAndImageTheImageMustBeLoad(self):\n",
    "        image = cv2.imread('/home/luis/dataset/' + '001' + '/' + '001001.jpg')\n",
    "        image = cv2.resize(image, (96, 96))\n",
    "        image2 = img_to_array(image)\n",
    "        image1 = load_image('001001.jpg')\n",
    "        self.asserEqual(image1,image2)\n",
    "    def WhenIHaveMyTripletsIWantToLoadIt(slef):\n",
    "        triplets = triples_batch(1,image_triples)\n",
    "        images = np.empty([1,3,96,96,3])\n",
    "        for index,i in enumerate(image_triples):\n",
    "            ahs, phs, nhs= i\n",
    "            a = (load_image(ahs),load_image(phs),load_image(nhs))\n",
    "            images[index] = a\n",
    "        self.asserEqual(triplets,images)\n",
    "    def WhenIWantToReshapeMyTripletsThisMustBeReshape(self):\n",
    "        triples_data = create_triplet(1)\n",
    "        image_cache = {}\n",
    "        tr_load_train = triples_batch(tr_train)\n",
    "        tr_load_train_ = reshape(tr_load_train,(96,96,3))\n",
    "        self.asserEqual(tr_load_val_a.shape,(96,96,3))\n",
    "    def WhenIWantToCalculateTheLoss(self):\n",
    "        y_true = 1\n",
    "        triples_data = create_triplet(1)\n",
    "        image_cache = {}\n",
    "        tr_load_train = triples_batch(tr_train)\n",
    "        y_pred = reshape(tr_load_train,(96,96,3))\n",
    "        loss = triple_loss(y_true, y_pred)\n",
    "        self.asserEqual(loss,0)\n",
    "    \n",
    "    def WhenIWantToCalculateTheCosineDistance(self):\n",
    "        y_true = 1\n",
    "        triples_data = create_triplet(1)\n",
    "        image_cache = {}\n",
    "        tr_load_train = triples_batch(tr_train)\n",
    "        y_pred = reshape(tr_load_train,(96,96,3))\n",
    "        distance = distance_vec(y_pred)\n",
    "        self.asserEqual(distance,0)\n",
    "\n",
    "  \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HksRdHOBGsiX"
   },
   "source": [
    "### **Funcion para crear tripletas y cargar las imagenes**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlov2ltiHFGo"
   },
   "outputs": [],
   "source": [
    "def get_random_image(img_groups, group_names, gid):\n",
    "    gname = group_names[gid]\n",
    "    photos = img_groups[gname]\n",
    "    pid = np.random.choice(np.arange(len(photos)), size=1)[0]\n",
    "    pname = photos[pid]\n",
    "    return gname + pname + \".jpg\"\n",
    "   \n",
    "def create_triplet(number_images): # Crea tripleta\n",
    "  img_groups = {}\n",
    "  for folder in  os.listdir('/home/luis/dataset'):\n",
    "    i = 0 \n",
    "    for img_file in os.listdir('/home/luis/dataset/' + folder):\n",
    "      if i == number_images: # Para solo coger 40 fotos\n",
    "        break\n",
    "      prefix, suffix = img_file.split(\".\")\n",
    "      pid = prefix[3:]\n",
    "      if folder in img_groups:\n",
    "          img_groups[folder].append(pid)\n",
    "      else:\n",
    "          img_groups[folder] = [pid]\n",
    "      i += 1\n",
    "  pos_triples, neg_triples, labels = [], [], []\n",
    "  # positive pairs and negative \n",
    "  group_names = list(img_groups.keys())\n",
    "  for key in img_groups.keys():\n",
    "    for i in range(0,number_images):\n",
    "      for j in range(i+1,number_images): # Si dejo i me cogeria duplas con elementos iguales osea (001,001)\n",
    "        inc = random.randrange(1, classes+1)\n",
    "        dn = (int(key) + inc) % classes\n",
    "        right = get_random_image(img_groups, group_names, dn)\n",
    "        pos_triples.append((key + img_groups[key][i] + \".jpg\", key + img_groups[key][j] + \".jpg\", right))\n",
    "  return pos_triples  \n",
    "\n",
    "def load_image(image_name):\n",
    "    image = cv2.imread('/home/luis/dataset/' + image_name[0:3] + '/' + image_name)\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = img_to_array(image)\n",
    "    return image     \n",
    "           \n",
    "def triples_batch(tamaño,image_triples):#, batch_size): #Tripletas\n",
    "    images = np.empty([tamaño,3,96,96,3])\n",
    "    for index,i in enumerate(image_triples):\n",
    "        ahs, phs, nhs= i\n",
    "        a = (load_image(ahs),load_image(phs),load_image(nhs))\n",
    "        images[index] = a\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_image(img_groups, group_names, gid):     #Este metodo es para juntar todas con todas\n",
    "    gname = group_names[gid]\n",
    "    photos = img_groups[gname]\n",
    "    pid = np.random.choice(np.arange(len(photos)), size=1)[0]\n",
    "    pname = photos[pid]\n",
    "    return gname + pname + \".jpg\"\n",
    "   \n",
    "def create_triplet(number_images): # Crea tripleta\n",
    "  img_groups = {}\n",
    "  for folder in  os.listdir('/home/luis/dataset3'):\n",
    "    i = 0 \n",
    "    for img_file in os.listdir('/home/luis/dataset3/' + folder):\n",
    "      if i == number_images: # Para solo coger 40 fotos\n",
    "        break\n",
    "      prefix, suffix = img_file.split(\".\")\n",
    "      pid = prefix[3:]\n",
    "      if folder in img_groups:\n",
    "          img_groups[folder].append(pid)\n",
    "      else:\n",
    "          img_groups[folder] = [pid]\n",
    "      i += 1\n",
    "  pos_triples = []\n",
    "  # positive pairs and negative \n",
    "  group_names = list(img_groups.keys())\n",
    "  for key in img_groups.keys():\n",
    "    for i in range(0,number_images):\n",
    "        for j in range(i+1,number_images): # Si dejo i me cogeria duplas con elementos iguales osea (001,001)\n",
    "            for k in img_groups.keys():\n",
    "                if k != key:\n",
    "                    for l in range(0,number_images):\n",
    "                        pos_triples.append((key + img_groups[key][i] + \".jpg\", key + img_groups[key][j] + \".jpg\", k + img_groups[k][l]))\n",
    "  return pos_triples\n",
    "\n",
    "def load_image(image_name):\n",
    "    image = cv2.imread('/home/luis/dataset3/' + image_name[0:3] + '/' + image_name)\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = img_to_array(image)\n",
    "    return image     \n",
    "           \n",
    "def triples_batch(tamaño,image_triples):#, batch_size): #Tripletas\n",
    "    images = np.empty([tamaño,3,96,96,3])\n",
    "    for index,i in enumerate(image_triples):\n",
    "        ahs, phs, nhs= i\n",
    "        a = (load_image(ahs),load_image(phs),load_image(nhs))\n",
    "        images[index] = a\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aniGPta3HVE7"
   },
   "source": [
    "### **Crear red neuronal Convolucional**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlIPAdDyHRcz"
   },
   "outputs": [],
   "source": [
    "def create_base_network(input_dim, classes): # SmallerVGGnet\n",
    "  red = Sequential() \n",
    "  red.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=input_dim))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "  #red.add(Dropout(0.25))\n",
    "  \n",
    "  # (CONV => RELU) * 2 => POOL\n",
    "  red.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  #red.add(Dropout(0.25))\n",
    "  \n",
    "  # (CONV => RELU) * 2 => POOL\n",
    "  red.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization(axis=-1))\n",
    "  red.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  #red.add(Dropout(0.25))\n",
    "  \n",
    "\t# first (and only) set of FC => RELU layers\n",
    "  red.add(Flatten())\n",
    "  red.add(Dense(2048))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization())\n",
    "  red.add(Dropout(0.5))\n",
    "\n",
    "  red.add(Dense(1024))\n",
    "  red.add(Activation(\"relu\"))\n",
    "  red.add(BatchNormalization())\n",
    "  red.add(Dropout(0.5))\n",
    "\n",
    "  return red "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVpDskYQqno1"
   },
   "source": [
    "## **Principal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EePEpaNqw4a"
   },
   "source": [
    "### **Inicializar datos y normalizarlos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1550100187214,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "DbZ40Cjvp5HQ",
    "outputId": "ae4cc33e-7155-40a9-d5e8-6b8abc80d469"
   },
   "outputs": [],
   "source": [
    "number_images = 40 # Numero de imagenes cogidas\n",
    "classes = 151 # Numero de pokemones\n",
    "batch = 32\n",
    "nb_epoch = 10\n",
    "\n",
    "input_dim = (96,96,3) # Son el ancho el alto y la profundidad de la imagen, 3 al ser en color es la variable input_dim pero todavia no esta tocada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vDF1KvPet_Gy"
   },
   "source": [
    "### Crear varias imagenes apartir de una moviendola o rotandola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes = ['001','002','003','004','005','006','007','008','009',\n",
    "            '010','011','012','013','014','015','016','017','018','019',\n",
    "            '020','021','022','023','024','025','026','027','028','029',\n",
    "            '030','031','032','033','034','035','036','037','038','039',\n",
    "            '040','041','042','043','044','045','046','047','048','049',\n",
    "            '050','051','052','053','054','055','056','057','058','059',\n",
    "            '060','061','062','063','064','065','066','067','068','069',\n",
    "            '070','071','072','073','074','075','076','077','078','079',\n",
    "            '080','081','082','083','084','085','086','087','088','089',\n",
    "            '090','091','092','093','094','095','096','097','098','099',\n",
    "            '100','101','102','103','104','105','106','107','108','109',\n",
    "            '110','111','112','113','114','115','116','117','118','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129',\n",
    "            '130','131','132','133','134','135','136','137','138','139',\n",
    "            '140','141','142','143','144','145','146','147','148','149',\n",
    "            '150','151']\n",
    "\n",
    "def load_image(image_name,i):\n",
    "    image = cv2.imread('/home/luis/dataset/' + image_name + '/' + image_name + i + '.jpg')\n",
    "    print('/home/luis/dataset/' + image_name + '/' + image_name + i + '.jpg')\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = img_to_array(image)\n",
    "    return image    \n",
    "           \n",
    "def triples_batch(tamaño):#, batch_size): #Tripletas\n",
    "    images = np.empty([tamaño,3,96,96,3])\n",
    "    for index,i in enumerate(image_triples):\n",
    "        ahs, phs, nhs= i\n",
    "        a = (load_image(ahs),load_image(phs),load_image(nhs))\n",
    "        images[index] = a\n",
    "    return images\n",
    "\n",
    "a = triples_batch(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXrC8WJ_kmdZ"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/home/luis/dataset',  # this is the target directory\n",
    "        target_size=(256, 256),  # all images will be resized to 150x150\n",
    "        batch_size=16,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#X_train = X_train.reshape(60000, input_dim)\n",
    "#X_test = X_test.reshape(10000, input_dim)\n",
    "#X_train = X_train.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_t5-FJBqAMK"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('/home/luis/database/108.png')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,save_to_dir='/home/luis/', save_prefix='1', save_format='png'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9SCO5vqq78g"
   },
   "source": [
    "### **Crear conjuntos de datos de entrenamiento y test** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGB199xDq8bn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "triples_data = create_triplet(number_images)\n",
    "\n",
    "print(\"# image triples:\", len(triples_data))\n",
    "\n",
    "tm_train = 20000\n",
    "tm_val = 28690\n",
    "\n",
    "tr_train = triples_data[0:tm_train]\n",
    "tr_val = triples_data[tm_train:tm_val]  #El tamaño tiene que ser par (No se mucho por que)\n",
    "\n",
    "print(\"# image triples:\", len(tr_train))\n",
    "print(\"# image triples:\", len(tr_val))\n",
    "\n",
    "image_cache = {}\n",
    "\n",
    "tr_load_train = triples_batch(20000,tr_train)\n",
    "tr_load_val = triples_batch(28690,tr_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1550052298257,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "5XMvIFWd7N45",
    "outputId": "9a0e13bd-f0f4-4fe3-d38c-69f833f5d495",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"# image train triples:\", len(tr_train))\n",
    "[x for x in tr_train[0:5]]\n",
    "\n",
    "print(\"# image validation triples:\", len(tr_val))\n",
    "[x for x in tr_val[0:5]]\n",
    "\n",
    "print(tr_load_train.shape)\n",
    "\n",
    "print(tr_load_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ya7x2IZ4q8mN"
   },
   "source": [
    "### **Crear red siamesa** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3908,
     "status": "ok",
     "timestamp": 1550052305912,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "Tk9pKrRhq8xL",
    "outputId": "2b360ebc-1ccf-4c67-edb6-c2b6caed1f99"
   },
   "outputs": [],
   "source": [
    "# network definition\n",
    "base_network = create_base_network(input_dim, classes)\n",
    "#base_network.summary()\n",
    "\n",
    "\n",
    "anchor_a = Input(shape=(input_dim))   #Nos da un tensor del tamaño input_dim\n",
    "anchor_p = Input(shape=(input_dim))\n",
    "anchor_n = Input(shape=(input_dim))\n",
    "\n",
    "\n",
    "processed_a = base_network(anchor_a)\n",
    "processed_p = base_network(anchor_p)\n",
    "processed_n = base_network(anchor_n)\n",
    "\n",
    "distance = Lambda(distance_vec, output_shape=abs_diff_output_shape)([processed_a, processed_p, processed_n])\n",
    "\n",
    "pred = Dense(1, activation = 'sigmoid')(distance)\n",
    "\n",
    "model = Model(inputs=[anchor_a, anchor_p, anchor_n], outputs=pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dlSqy90sq89q"
   },
   "source": [
    "### **Entrenar modelo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(data,dim):\n",
    "  data_a = data[:, 0].reshape(-1, dim[0], dim[1], dim[2])\n",
    "  data_p = data[:, 1].reshape(-1, dim[0], dim[1], dim[2])\n",
    "  data_n = data[:, 2].reshape(-1, dim[0], dim[1], dim[2])\n",
    "  return [data_a,data_p,data_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nDUFYuEAB9u",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Datos de entrenamiento\n",
    "\n",
    "tr_load_train_ = reshape(tr_load_train,input_dim)\n",
    "tr_load_train_a = tr_load_train_[0]\n",
    "tr_load_train_p = tr_load_train_[1]\n",
    "tr_load_train_n = tr_load_train_[2]\n",
    "\n",
    "print(tr_load_train_a.shape)\n",
    "print(tr_load_train_p.shape)\n",
    "print(tr_load_train_n.shape)\n",
    "\n",
    "#Datos de validacion\n",
    "\n",
    "tr_load_val_ = reshape(tr_load_val,input_dim)\n",
    "tr_load_val_a = tr_load_val_[0]\n",
    "tr_load_val_p = tr_load_val_[1]\n",
    "tr_load_val_n = tr_load_val_[2]\n",
    "\n",
    "print(tr_load_val_a.shape)\n",
    "print(tr_load_val_p.shape)\n",
    "print(tr_load_val_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1550052350856,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "str8zx0HBFXP",
    "outputId": "e43ddd6e-351c-438f-d702-71d3a8dc48a2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3\n",
    "EPOCHS = 100\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=triple_loss, optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAikSlsZEBOI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = np.ones(len(tr_load_train))\n",
    "val = np.ones(len(tr_load_val))\n",
    "a = model.fit([tr_load_train_a,tr_load_train_a,tr_load_train_a], train, batch_size=batch, epochs=nb_epoch, validation_data=([tr_load_val_a,tr_load_val_p,tr_load_val_n], val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1500,
     "status": "ok",
     "timestamp": 1550080484838,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "JLhDWbl_T36_",
    "outputId": "d43db674-e4fd-4167-87d8-d8893445631b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(a.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(a.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(a.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(a.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = load_model('my_model.h5', custom_objects={'triple_loss': triple_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paZXfyDSr0VW"
   },
   "source": [
    "# **Test y prueba en funcionamiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaGMjjXCr6W4"
   },
   "source": [
    "## **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t07kR9viKzMe"
   },
   "outputs": [],
   "source": [
    "def load_data(name, file):\n",
    "  if file == 1:\n",
    "    image = cv2.imread('/home/luis/database/' + name + '.jpg')\n",
    "  else:\n",
    "    image = cv2.imread('/home/luis/' + name + '.jpg')\n",
    "  image = cv2.resize(image, (96, 96))\n",
    "  image = img_to_array(image)\n",
    "  return image  \n",
    "\n",
    "def evaluate_data(name):\n",
    "  values = []\n",
    "  for i in range(1,classes+1):\n",
    "    images = []\n",
    "    name1 = str(i)\n",
    "    len_name = len(name1)\n",
    "    if len_name == 1:\n",
    "      name1= '00' + name1\n",
    "    elif len_name == 2:\n",
    "      name1= '0' + name1\n",
    "    #print(name + ' ' + name1 + ' ' + name1)\n",
    "    images.append((load_data(name, 0),load_data(name1, 1),load_data(name1, 1)))\n",
    "    data = np.array(images, dtype=\"float\") / 255.0\n",
    "    data = reshape(data,input_dim)\n",
    "    a = model.predict([data[0],data[1],data[2]])\n",
    "    #print(a)\n",
    "    values.append(a)\n",
    "  return values\n",
    "\n",
    "def draw_image(subplot, image, title):\n",
    "    plt.subplot(subplot)\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "def compare(array1,array2):\n",
    "    a = 0\n",
    "    for i in range(1,(len(array1))):\n",
    "        if array1[i] == array2[i]:\n",
    "            a = a + 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[2.350485e-08]]\n",
      "1 [[2.3490687e-08]]\n",
      "2 [[2.3382775e-08]]\n",
      "3 [[2.3252378e-08]]\n",
      "4 [[2.322082e-08]]\n",
      "5 [[2.327576e-08]]\n",
      "6 [[2.3431395e-08]]\n",
      "7 [[2.330379e-08]]\n",
      "8 [[2.3409326e-08]]\n",
      "9 [[2.3459524e-08]]\n",
      "10 [[2.3437162e-08]]\n",
      "11 [[2.328744e-08]]\n",
      "12 [[2.3301656e-08]]\n",
      "13 [[2.3258542e-08]]\n",
      "14 [[2.3199837e-08]]\n",
      "15 [[2.3343562e-08]]\n",
      "16 [[2.326311e-08]]\n",
      "17 [[2.3238764e-08]]\n",
      "18 [[2.3257567e-08]]\n",
      "19 [[2.3334033e-08]]\n",
      "20 [[2.3256812e-08]]\n",
      "21 [[2.3245324e-08]]\n",
      "22 [[2.3488536e-08]]\n",
      "23 [[2.34154e-08]]\n",
      "24 [[2.3244526e-08]]\n",
      "25 [[2.321803e-08]]\n",
      "26 [[2.3354694e-08]]\n",
      "27 [[2.3362848e-08]]\n",
      "28 [[2.3350598e-08]]\n",
      "29 [[2.3308502e-08]]\n",
      "30 [[2.3432781e-08]]\n",
      "31 [[2.3424377e-08]]\n",
      "32 [[2.334503e-08]]\n",
      "33 [[2.326826e-08]]\n",
      "34 [[2.3283485e-08]]\n",
      "35 [[2.3260183e-08]]\n",
      "36 [[2.3372476e-08]]\n",
      "37 [[2.3226578e-08]]\n",
      "38 [[2.3261116e-08]]\n",
      "39 [[2.3240627e-08]]\n",
      "40 [[2.3263288e-08]]\n",
      "41 [[2.3302812e-08]]\n",
      "42 [[2.3406425e-08]]\n",
      "43 [[2.3311925e-08]]\n",
      "44 [[2.327607e-08]]\n",
      "45 [[2.3251712e-08]]\n",
      "46 [[2.3282553e-08]]\n",
      "47 [[2.3324958e-08]]\n",
      "48 [[2.3196915e-08]]\n",
      "49 [[2.3448697e-08]]\n",
      "50 [[2.344199e-08]]\n",
      "51 [[2.3216746e-08]]\n",
      "52 [[2.3197666e-08]]\n",
      "53 [[2.3245859e-08]]\n",
      "54 [[2.3284018e-08]]\n",
      "55 [[2.3191872e-08]]\n",
      "56 [[2.3321265e-08]]\n",
      "57 [[2.3268967e-08]]\n",
      "58 [[2.3329719e-08]]\n",
      "59 [[2.340531e-08]]\n",
      "60 [[2.3353047e-08]]\n",
      "61 [[2.3250868e-08]]\n",
      "62 [[2.3206741e-08]]\n",
      "63 [[2.3263512e-08]]\n",
      "64 [[2.324209e-08]]\n",
      "65 [[2.3253884e-08]]\n",
      "66 [[2.3293259e-08]]\n",
      "67 [[2.3292458e-08]]\n",
      "68 [[2.3229015e-08]]\n",
      "69 [[2.3293925e-08]]\n",
      "70 [[2.3354874e-08]]\n",
      "71 [[2.3261869e-08]]\n",
      "72 [[2.3249981e-08]]\n",
      "73 [[2.320882e-08]]\n",
      "74 [[2.3214488e-08]]\n",
      "75 [[2.3373678e-08]]\n",
      "76 [[2.3208068e-08]]\n",
      "77 [[2.3206075e-08]]\n",
      "78 [[2.3243064e-08]]\n",
      "79 [[2.3247498e-08]]\n",
      "80 [[2.3201649e-08]]\n",
      "81 [[2.3278956e-08]]\n",
      "82 [[2.331437e-08]]\n",
      "83 [[2.3183823e-08]]\n",
      "84 [[2.3217055e-08]]\n",
      "85 [[2.3216568e-08]]\n",
      "86 [[2.3212761e-08]]\n",
      "87 [[2.3272564e-08]]\n",
      "88 [[2.3226756e-08]]\n",
      "89 [[2.3457016e-08]]\n",
      "90 [[2.3402496e-08]]\n",
      "91 [[2.3507853e-08]]\n",
      "92 [[2.3263246e-08]]\n",
      "93 [[2.3476174e-08]]\n",
      "94 [[2.3363919e-08]]\n",
      "95 [[2.338438e-08]]\n",
      "96 [[2.3258453e-08]]\n",
      "97 [[2.3218252e-08]]\n",
      "98 [[2.3211477e-08]]\n",
      "99 [[2.333724e-08]]\n",
      "100 [[2.333052e-08]]\n",
      "101 [[2.320997e-08]]\n",
      "102 [[2.3290326e-08]]\n",
      "103 [[2.3273275e-08]]\n",
      "104 [[2.3254549e-08]]\n",
      "105 [[2.3239608e-08]]\n",
      "106 [[2.3215152e-08]]\n",
      "107 [[2.3274163e-08]]\n",
      "108 [[2.3289616e-08]]\n",
      "109 [[2.3254282e-08]]\n",
      "110 [[2.3460192e-08]]\n",
      "111 [[2.3304102e-08]]\n",
      "112 [[2.322525e-08]]\n",
      "113 [[2.3567383e-08]]\n",
      "114 [[2.335278e-08]]\n",
      "115 [[2.3312904e-08]]\n",
      "116 [[2.3285528e-08]]\n",
      "117 [[2.3174938e-08]]\n",
      "118 [[2.3259961e-08]]\n",
      "119 [[2.3365521e-08]]\n",
      "120 [[2.3392946e-08]]\n",
      "121 [[2.3292369e-08]]\n",
      "122 [[2.323646e-08]]\n",
      "123 [[2.3261205e-08]]\n",
      "124 [[2.3273541e-08]]\n",
      "125 [[2.3274383e-08]]\n",
      "126 [[2.328162e-08]]\n",
      "127 [[2.3256591e-08]]\n",
      "128 [[2.32569e-08]]\n",
      "129 [[2.3267017e-08]]\n",
      "130 [[2.3363606e-08]]\n",
      "131 [[2.3355318e-08]]\n",
      "132 [[2.3346455e-08]]\n",
      "133 [[2.3355852e-08]]\n",
      "134 [[2.3267372e-08]]\n",
      "135 [[2.328584e-08]]\n",
      "136 [[2.3345608e-08]]\n",
      "137 [[2.3398526e-08]]\n",
      "138 [[2.3355497e-08]]\n",
      "139 [[2.3491403e-08]]\n",
      "140 [[2.3254948e-08]]\n",
      "141 [[2.3197448e-08]]\n",
      "142 [[2.332122e-08]]\n",
      "143 [[2.3316595e-08]]\n",
      "144 [[2.319988e-08]]\n",
      "145 [[2.3172197e-08]]\n",
      "146 [[2.3220732e-08]]\n",
      "147 [[2.3243109e-08]]\n",
      "148 [[2.3222636e-08]]\n",
      "149 [[2.3210502e-08]]\n",
      "150 [[2.3179402e-08]]\n",
      "145 [[2.3172197e-08]]\n"
     ]
    }
   ],
   "source": [
    "x = evaluate_data('001')\n",
    "for index,i in enumerate(x):\n",
    "    print(index,i)\n",
    "var = 1000\n",
    "index_var = 0\n",
    "for index,j in enumerate(x):\n",
    "     if j <= var:\n",
    "        var = j\n",
    "        index_var=index\n",
    "print(index_var,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ",'006','007','008','009',\n",
    "            '010','011','012','013','014','015','016','017','018','019',\n",
    "            '020','021','022','023','024','025','026','027','028','029',\n",
    "            '030','031','032','033','034','035','036','037','038','039',\n",
    "            '040','041','042','043','044','045','046','047','048','049',\n",
    "            '050','051','052','053','054','055','056','057','058','059',\n",
    "            '060','061','062','063','064','065','066','067','068','069',\n",
    "            '070','071','072','073','074','075','076','077','078','079',\n",
    "            '080','081','082','083','084','085','086','087','088','089',\n",
    "            '090','091','092','093','094','095','096','097','098','099','100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76juyf6xYvh9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imagenes = ['001','002','003','004','005']\n",
    "\n",
    "values = []\n",
    "for i in range(0,5):\n",
    "    x = evaluate_data(imagenes[i])\n",
    "    values.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1550081622680,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "j_-e1d8lsDtO",
    "outputId": "12e5212c-a5a6-4925-fe0c-9a4da243d81e"
   },
   "outputs": [],
   "source": [
    "aciertos = []\n",
    "for i in values:\n",
    "    var = 1000\n",
    "    index_var = 0\n",
    "    for index,j in enumerate(i):\n",
    "        if j <= var:\n",
    "            var = j\n",
    "            index_var=index\n",
    "    print(index_var,var)\n",
    "    aciertos.append(index_var)\n",
    "    #ref_image = plt.imread(os.path.join('/home/luis/dataset/' + index_var + '.png'))\n",
    "    #draw_image(131,ref_image, \"Pokemon\")\n",
    "    \n",
    " \n",
    "#Accuracy y Matriz de confusión\n",
    "imagenes = list(map(int, imagenes))\n",
    "accuracy = compare(aciertos, imagenes)\n",
    "print('El % de aciertos es: ', accuracy/100, '%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "Q9gjsvw88430",
    "vDF1KvPet_Gy"
   ],
   "name": "TFG Software.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
