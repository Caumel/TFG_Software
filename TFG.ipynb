{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1550100164594,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "5UhweCKcBoOo",
    "outputId": "944cd4bb-c8af-47b9-aeb4-b24f41019cf9"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import,division,print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from PIL import Image as img\n",
    "import cv2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda, Flatten, Activation\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1550100187214,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "DbZ40Cjvp5HQ",
    "outputId": "ae4cc33e-7155-40a9-d5e8-6b8abc80d469"
   },
   "outputs": [],
   "source": [
    "number_images = 40 # Numero de imagenes\n",
    "classes = 5 # Numero de pokemones\n",
    "batch = 32\n",
    "nb_epoch = 30\n",
    "teta = 0.9\n",
    "\n",
    "input_dim = (96,96,3) # Son el ancho el alto y la profundidad de la imagen, 3 al ser en color es la variable input_dim pero todavia no esta tocada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH1ZRvQPDtCc"
   },
   "outputs": [],
   "source": [
    "def abs_diff_output_shape(input_shapes):\n",
    "    shape1, shape2, shape3= input_shapes\n",
    "    return shape1\n",
    "\n",
    "def distance_vec(y_pred): #Cosine distance\n",
    "    x = y_pred[0]\n",
    "    y = y_pred[1]\n",
    "    z = y_pred[2]\n",
    "    negative = K.prod(K.stack([x, y], axis=1), axis=1)\n",
    "    return negative\n",
    "\n",
    "def get_abs_diff(y_pred):\n",
    "    x = y_pred[0]\n",
    "    y = y_pred[1]\n",
    "    z = y_pred[2]\n",
    "    return K.abs(x - y)\n",
    "\n",
    "def triple_loss(y_true, y_pred):   # y_pred contiene la imagen ancla, positiva y negativa\n",
    "    alpha = 0.1\n",
    "  \n",
    "    anchor = y_pred[0]\n",
    "    positive = y_pred[1]\n",
    "    negative = y_pred[2]\n",
    "    \n",
    "    positive_distance = K.mean(K.square(anchor-positive),axis=-1)  #En principio mean y sum hacen lo mismo excepto que una hace media y otro suma\n",
    "    negative_distance = K.mean(K.square(anchor-negative),axis=-1)\n",
    "  \n",
    "    loss = positive_distance - negative_distance\n",
    "    return K.maximum(loss + alpha, 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlov2ltiHFGo"
   },
   "outputs": [],
   "source": [
    "def get_random_image(img_groups, group_names, gid):\n",
    "    gname = group_names[gid]\n",
    "    photos = img_groups[gname]\n",
    "    pid = np.random.choice(np.arange(len(photos)), size=1)[0]\n",
    "    pname = photos[pid]\n",
    "    return gname + pname + \".jpg\"\n",
    "   \n",
    "def create_triplet(number_images,minImage,maxImage): # Crea tripleta\n",
    "  img_groups = {}\n",
    "  for folder in  sorted(os.listdir('/home/luis/dataset2'),reverse=False):\n",
    "    i = 0 \n",
    "    for img_file in sorted(os.listdir('/home/luis/dataset2/' + folder),reverse=False):\n",
    "      #if i == number_images: # Para solo coger 40 fotos\n",
    "        #break\n",
    "      if i < minImage:\n",
    "        i = i + 1\n",
    "        continue\n",
    "      if i > maxImage:\n",
    "        break\n",
    "      prefix, suffix = img_file.split(\".\")\n",
    "      pid = prefix[3:]\n",
    "      if folder in img_groups:\n",
    "          img_groups[folder].append(pid)\n",
    "      else:\n",
    "          img_groups[folder] = [pid]\n",
    "      i += 1\n",
    "  pos_triples, neg_triples, labels = [], [], []\n",
    "  # positive pairs and negative \n",
    "  group_names = list(img_groups.keys())\n",
    "  for key in img_groups.keys():\n",
    "    for i in range(0,number_images):\n",
    "      for j in range(i+1,number_images): # Si dejo i me cogeria duplas con elementos iguales osea (001,001)\n",
    "        inc = random.randrange(1, classes+1)\n",
    "        dn = (int(key) + inc) % classes\n",
    "        right = get_random_image(img_groups, group_names, dn)\n",
    "        pos_triples.append((key + img_groups[key][i] + \".jpg\", key + img_groups[key][j] + \".jpg\", right))\n",
    "  return pos_triples  \n",
    "def load_image(image_name):\n",
    "    image = cv2.imread('/home/luis/dataset/' + image_name[0:3] + '/' + image_name)\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0\n",
    "    return image     \n",
    "           \n",
    "def triples_batch(tamaño,image_triples):#, batch_size): #Tripletas\n",
    "    images = np.empty([tamaño,3,96,96,3],dtype=\"float16\")\n",
    "    for index,i in enumerate(image_triples):\n",
    "        ahs, phs, nhs= i\n",
    "        a = (load_image(ahs),load_image(phs),load_image(nhs))\n",
    "        images[index] = a\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_image2(img_groups, group_names, gid):     #Este metodo es para juntar todas con todas\n",
    "    gname = group_names[gid]\n",
    "    photos = img_groups[gname]\n",
    "    pid = np.random.choice(np.arange(len(photos)), size=1)[0]\n",
    "    pname = photos[pid]\n",
    "    return gname + pname + \".jpg\"\n",
    "   \n",
    "def create_triplet2(number_images,minImage,maxImage): # Crea tripleta\n",
    "    img_groups = {}\n",
    "    for folder in  sorted(os.listdir('/home/luis/dataset2'),reverse=False):\n",
    "        i = 0 \n",
    "        for img_file in sorted(os.listdir('/home/luis/dataset2/' + folder),reverse=False):\n",
    "          #if i == number_images: # Para solo coger 40 fotos\n",
    "            #break\n",
    "            if i < minImage:\n",
    "                i = i + 1\n",
    "                continue\n",
    "            if i > maxImage:\n",
    "                break\n",
    "            print(img_file)\n",
    "            prefix, suffix = img_file.split(\".\")\n",
    "            pid = prefix[3:]\n",
    "            if folder in img_groups:\n",
    "                 img_groups[folder].append(pid)\n",
    "            else:\n",
    "                 img_groups[folder] = [pid]\n",
    "            i += 1\n",
    "    pos_triples = []\n",
    "      # positive pairs and negative \n",
    "    group_names = list(img_groups.keys())\n",
    "    for key in img_groups.keys():\n",
    "        for i in range(0,number_images):\n",
    "            for j in range(i+1,number_images): # Si dejo i me cogeria duplas con elementos iguales osea (001,001)\n",
    "                for k in img_groups.keys():\n",
    "                    if k != key:\n",
    "                        for l in range(0,number_images):\n",
    "                            print((key + img_groups[key][i] + \".jpg\", key + img_groups[key][j] + \".jpg\", k + img_groups[k][l]))\n",
    "                            pos_triples.append((key + img_groups[key][i] + \".jpg\", key + img_groups[key][j] + \".jpg\", k + img_groups[k][l]))\n",
    "    return pos_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlIPAdDyHRcz"
   },
   "outputs": [],
   "source": [
    "def create_base_network(input_dim, classes): # SmallerVGGnet\n",
    "    red = Sequential() \n",
    "    red.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=input_dim))\n",
    "    red.add(Activation(\"relu\"))\n",
    "    red.add(BatchNormalization(axis=-1))\n",
    "    red.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    #red.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    red.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    red.add(Activation(\"relu\"))\n",
    "    red.add(BatchNormalization(axis=-1))\n",
    "    red.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    red.add(Activation(\"relu\"))\n",
    "    red.add(BatchNormalization(axis=-1))\n",
    "    red.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #red.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    red.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    red.add(Activation(\"relu\"))\n",
    "    red.add(BatchNormalization(axis=-1))\n",
    "    red.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    red.add(Activation(\"relu\"))\n",
    "    red.add(BatchNormalization(axis=-1))\n",
    "    red.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #red.add(Dropout(0.25))\n",
    "\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    red.add(Flatten())\n",
    "    #red.add(Dense(2048))\n",
    "    #red.add(Activation(\"relu\"))\n",
    "    #red.add(BatchNormalization())\n",
    "    #red.add(Dropout(0.5))\n",
    "\n",
    "    red.add(Dense(1024))\n",
    "    red.add(Activation(\"relu\"))\n",
    "    red.add(BatchNormalization())\n",
    "    red.add(Dropout(0.5))\n",
    "\n",
    "    return red "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGB199xDq8bn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "triples_data = create_triplet(number_images,0,number_images)\n",
    "\n",
    "print(\"# image triples:\", len(triples_data))\n",
    "\n",
    "tm_train = 3000\n",
    "tm_val = 3900\n",
    "\n",
    "tr_train = triples_data[0:tm_train]\n",
    "tr_val = triples_data[tm_train:tm_val]  #El tamaño tiene que ser par (No se mucho por que)\n",
    "\n",
    "print(\"# image triples:\", len(tr_train))\n",
    "print(\"# image triples:\", len(tr_val))\n",
    "\n",
    "image_cache = {}\n",
    "\n",
    "tr_load_train = triples_batch(800,tr_train)\n",
    "tr_load_val = triples_batch(106,tr_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1550052298257,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "5XMvIFWd7N45",
    "outputId": "9a0e13bd-f0f4-4fe3-d38c-69f833f5d495",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# image train triples: 800\n",
      "# image validation triples: 106\n",
      "(800, 3, 96, 96, 3)\n",
      "(106, 3, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"# image train triples:\", len(tr_train))\n",
    "[x for x in tr_train[0:5]]\n",
    "\n",
    "print(\"# image validation triples:\", len(tr_val))\n",
    "[x for x in tr_val[0:5]]\n",
    "\n",
    "print(tr_load_train.shape)\n",
    "\n",
    "print(tr_load_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3908,
     "status": "ok",
     "timestamp": 1550052305912,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "Tk9pKrRhq8xL",
    "outputId": "2b360ebc-1ccf-4c67-edb6-c2b6caed1f99"
   },
   "outputs": [],
   "source": [
    "# network definition\n",
    "base_network = create_base_network(input_dim, classes)\n",
    "#base_network.summary()\n",
    "\n",
    "\n",
    "anchor_a = Input(shape=(input_dim))   #Nos da un tensor del tamaño input_dim\n",
    "anchor_p = Input(shape=(input_dim))\n",
    "anchor_n = Input(shape=(input_dim))\n",
    "\n",
    "\n",
    "processed_a = base_network(anchor_a)\n",
    "processed_p = base_network(anchor_p)\n",
    "processed_n = base_network(anchor_n)\n",
    "\n",
    "distance = Lambda(distance_vec, output_shape=abs_diff_output_shape)([processed_a, processed_p, processed_n])\n",
    "\n",
    "pred = Dense(1, activation = 'sigmoid')(distance)\n",
    "\n",
    "model = Model(inputs=[anchor_a, anchor_p, anchor_n], outputs=pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(data,dim):\n",
    "    data_a = data[:, 0].reshape(-1, dim[0], dim[1], dim[2])\n",
    "    data_p = data[:, 1].reshape(-1, dim[0], dim[1], dim[2])\n",
    "    data_n = data[:, 2].reshape(-1, dim[0], dim[1], dim[2])\n",
    "    return [data_a,data_p,data_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nDUFYuEAB9u",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 96, 96, 3)\n",
      "(800, 96, 96, 3)\n",
      "(800, 96, 96, 3)\n",
      "(106, 96, 96, 3)\n",
      "(106, 96, 96, 3)\n",
      "(106, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "#Datos de entrenamiento\n",
    "\n",
    "tr_load_train_ = reshape(tr_load_train,input_dim)\n",
    "tr_load_train_a = tr_load_train_[0]\n",
    "tr_load_train_p = tr_load_train_[1]\n",
    "tr_load_train_n = tr_load_train_[2]\n",
    "\n",
    "print(tr_load_train_a.shape)\n",
    "print(tr_load_train_p.shape)\n",
    "print(tr_load_train_n.shape)\n",
    "\n",
    "#Datos de validacion\n",
    "\n",
    "tr_load_val_ = reshape(tr_load_val,input_dim)\n",
    "tr_load_val_a = tr_load_val_[0]\n",
    "tr_load_val_p = tr_load_val_[1]\n",
    "tr_load_val_n = tr_load_val_[2]\n",
    "\n",
    "print(tr_load_val_a.shape)\n",
    "print(tr_load_val_p.shape)\n",
    "print(tr_load_val_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1550052350856,
     "user": {
      "displayName": "Luis Caumel",
      "photoUrl": "",
      "userId": "08450739378384452972"
     },
     "user_tz": -60
    },
    "id": "str8zx0HBFXP",
    "outputId": "e43ddd6e-351c-438f-d702-71d3a8dc48a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1024)         8673152     input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1024)         0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "                                                                 sequential_2[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1025        lambda_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 8,674,177\n",
      "Trainable params: 8,671,297\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 100\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=triple_loss, optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gAikSlsZEBOI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 106 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 45s 57ms/step - loss: 0.1777 - acc: 0.3075 - val_loss: 0.1979 - val_acc: 0.2547\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 46s 58ms/step - loss: 0.2744 - acc: 0.2988 - val_loss: 0.4962 - val_acc: 0.2642\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 49s 61ms/step - loss: 0.2113 - acc: 0.1813 - val_loss: 0.3623 - val_acc: 0.5094\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 50s 63ms/step - loss: 0.1812 - acc: 0.1537 - val_loss: 0.6702 - val_acc: 0.3113\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.1634 - acc: 0.0975 - val_loss: 0.4810 - val_acc: 0.6604\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 50s 62ms/step - loss: 0.1080 - acc: 0.0537 - val_loss: 0.4018 - val_acc: 0.1604\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.0919 - acc: 0.0312 - val_loss: 0.6698 - val_acc: 0.2453\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 49s 61ms/step - loss: 0.1065 - acc: 0.0187 - val_loss: 0.1020 - val_acc: 0.2170\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 47s 59ms/step - loss: 0.0959 - acc: 0.0288 - val_loss: 0.4019 - val_acc: 0.3019\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 50s 62ms/step - loss: 0.1172 - acc: 0.0212 - val_loss: 0.3755 - val_acc: 0.2736\n"
     ]
    }
   ],
   "source": [
    "train = np.ones(len(tr_load_train))\n",
    "val = np.ones(len(tr_load_val))\n",
    "a = model.fit([tr_load_train_a,tr_load_train_p,tr_load_train_n], train, batch_size=batch, epochs=nb_epoch, validation_data=([tr_load_val_a,tr_load_val_p,tr_load_val_n], val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# image triples: 906\n",
      "# image triples: 800\n",
      "# image triples: 106\n",
      "Train on 800 samples, validate on 106 samples\n",
      "Epoch 1/10\n",
      "256/800 [========>.....................] - ETA: 26s - loss: 0.1000 - acc: 0.0039    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-cee412c0f43e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_load_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_load_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_load_train_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_load_train_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_load_train_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_load_val_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_load_val_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_load_val_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0,6):\n",
    "    #for i in range(0,(int)(40/number_images)):\n",
    "    #triples_data = create_triplet(number_images,i*number_images,i*number_images+number_images-1)\n",
    "\n",
    "    #print(\"# image triples:\", len(triples_data))\n",
    "\n",
    "    #tm_train = 800\n",
    "    #tm_val = 906\n",
    "\n",
    "    #tr_train = triples_data[0:tm_train]\n",
    "    #tr_val = triples_data[tm_train:tm_val]  #El tamaño tiene que ser par (No se mucho por que)\n",
    "\n",
    "    #print(\"# image triples:\", len(tr_train))\n",
    "    #print(\"# image triples:\", len(tr_val))\n",
    "\n",
    "    #tr_load_train = triples_batch(800,tr_train)\n",
    "    #tr_load_val = triples_batch(106,tr_val)\n",
    "\n",
    "    #Datos de entrenamiento\n",
    "\n",
    "    #tr_load_train_ = reshape(tr_load_train,input_dim)\n",
    "    #tr_load_train_a = tr_load_train_[0]\n",
    "    #tr_load_train_p = tr_load_train_[1]\n",
    "    #tr_load_train_n = tr_load_train_[2]\n",
    "\n",
    "    #Datos de validacion\n",
    "\n",
    "    #tr_load_val_ = reshape(tr_load_val,input_dim)\n",
    "    #tr_load_val_a = tr_load_val_[0]\n",
    "    #tr_load_val_p = tr_load_val_[1]\n",
    "    #tr_load_val_n = tr_load_val_[2]\n",
    "\n",
    "    train = np.ones(len(tr_load_train))\n",
    "    val = np.ones(len(tr_load_val))\n",
    "    a = model.fit([tr_load_train_p,tr_load_train_a,tr_load_train_n], train, batch_size=batch, epochs=nb_epoch, validation_data=([tr_load_val_a,tr_load_val_p,tr_load_val_n], val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "Q9gjsvw88430",
    "vDF1KvPet_Gy"
   ],
   "name": "TFG Software.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
